{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1WuTNgXKO__B"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fv6JXisSPbmz",
        "outputId": "78036e6c-7787-4b74-d7b8-2999a441fded"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
              " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.config.experimental.list_physical_devices()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "-5BghVD_Phz-",
        "outputId": "98e3cf73-db66-405a-93df-d70233574e15"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customerID</th>\n",
              "      <th>gender</th>\n",
              "      <th>SeniorCitizen</th>\n",
              "      <th>Partner</th>\n",
              "      <th>Dependents</th>\n",
              "      <th>tenure</th>\n",
              "      <th>PhoneService</th>\n",
              "      <th>MultipleLines</th>\n",
              "      <th>InternetService</th>\n",
              "      <th>OnlineSecurity</th>\n",
              "      <th>...</th>\n",
              "      <th>DeviceProtection</th>\n",
              "      <th>TechSupport</th>\n",
              "      <th>StreamingTV</th>\n",
              "      <th>StreamingMovies</th>\n",
              "      <th>Contract</th>\n",
              "      <th>PaperlessBilling</th>\n",
              "      <th>PaymentMethod</th>\n",
              "      <th>MonthlyCharges</th>\n",
              "      <th>TotalCharges</th>\n",
              "      <th>Churn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7590-VHVEG</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "      <td>No</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>DSL</td>\n",
              "      <td>No</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Electronic check</td>\n",
              "      <td>29.85</td>\n",
              "      <td>29.85</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5575-GNVDE</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>34</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>One year</td>\n",
              "      <td>No</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>56.95</td>\n",
              "      <td>1889.5</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3668-QPYBK</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>2</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>53.85</td>\n",
              "      <td>108.15</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7795-CFOCW</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>45</td>\n",
              "      <td>No</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>One year</td>\n",
              "      <td>No</td>\n",
              "      <td>Bank transfer (automatic)</td>\n",
              "      <td>42.30</td>\n",
              "      <td>1840.75</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9237-HQITU</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>2</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Fiber optic</td>\n",
              "      <td>No</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Electronic check</td>\n",
              "      <td>70.70</td>\n",
              "      <td>151.65</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
              "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
              "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
              "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
              "3  7795-CFOCW    Male              0      No         No      45           No   \n",
              "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
              "\n",
              "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
              "0  No phone service             DSL             No  ...               No   \n",
              "1                No             DSL            Yes  ...              Yes   \n",
              "2                No             DSL            Yes  ...               No   \n",
              "3  No phone service             DSL            Yes  ...              Yes   \n",
              "4                No     Fiber optic             No  ...               No   \n",
              "\n",
              "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
              "0          No          No              No  Month-to-month              Yes   \n",
              "1          No          No              No        One year               No   \n",
              "2          No          No              No  Month-to-month              Yes   \n",
              "3         Yes          No              No        One year               No   \n",
              "4          No          No              No  Month-to-month              Yes   \n",
              "\n",
              "               PaymentMethod MonthlyCharges  TotalCharges Churn  \n",
              "0           Electronic check          29.85         29.85    No  \n",
              "1               Mailed check          56.95        1889.5    No  \n",
              "2               Mailed check          53.85        108.15   Yes  \n",
              "3  Bank transfer (automatic)          42.30       1840.75    No  \n",
              "4           Electronic check          70.70        151.65   Yes  \n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('customer_churn.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "u0U7lJeZPwvq"
      },
      "outputs": [],
      "source": [
        "df.drop('customerID', axis='columns', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "nA7m6FCnP8l6",
        "outputId": "fdad751d-301a-4aa6-c73e-c271a0a10d77"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>SeniorCitizen</th>\n",
              "      <th>Partner</th>\n",
              "      <th>Dependents</th>\n",
              "      <th>tenure</th>\n",
              "      <th>PhoneService</th>\n",
              "      <th>MultipleLines</th>\n",
              "      <th>InternetService</th>\n",
              "      <th>OnlineSecurity</th>\n",
              "      <th>OnlineBackup</th>\n",
              "      <th>DeviceProtection</th>\n",
              "      <th>TechSupport</th>\n",
              "      <th>StreamingTV</th>\n",
              "      <th>StreamingMovies</th>\n",
              "      <th>Contract</th>\n",
              "      <th>PaperlessBilling</th>\n",
              "      <th>PaymentMethod</th>\n",
              "      <th>MonthlyCharges</th>\n",
              "      <th>TotalCharges</th>\n",
              "      <th>Churn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "      <td>No</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>DSL</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Electronic check</td>\n",
              "      <td>29.85</td>\n",
              "      <td>29.85</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>34</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>One year</td>\n",
              "      <td>No</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>56.95</td>\n",
              "      <td>1889.5</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>2</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>53.85</td>\n",
              "      <td>108.15</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>45</td>\n",
              "      <td>No</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>One year</td>\n",
              "      <td>No</td>\n",
              "      <td>Bank transfer (automatic)</td>\n",
              "      <td>42.30</td>\n",
              "      <td>1840.75</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>2</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Fiber optic</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Electronic check</td>\n",
              "      <td>70.70</td>\n",
              "      <td>151.65</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
              "0  Female              0     Yes         No       1           No   \n",
              "1    Male              0      No         No      34          Yes   \n",
              "2    Male              0      No         No       2          Yes   \n",
              "3    Male              0      No         No      45           No   \n",
              "4  Female              0      No         No       2          Yes   \n",
              "\n",
              "      MultipleLines InternetService OnlineSecurity OnlineBackup  \\\n",
              "0  No phone service             DSL             No          Yes   \n",
              "1                No             DSL            Yes           No   \n",
              "2                No             DSL            Yes          Yes   \n",
              "3  No phone service             DSL            Yes           No   \n",
              "4                No     Fiber optic             No           No   \n",
              "\n",
              "  DeviceProtection TechSupport StreamingTV StreamingMovies        Contract  \\\n",
              "0               No          No          No              No  Month-to-month   \n",
              "1              Yes          No          No              No        One year   \n",
              "2               No          No          No              No  Month-to-month   \n",
              "3              Yes         Yes          No              No        One year   \n",
              "4               No          No          No              No  Month-to-month   \n",
              "\n",
              "  PaperlessBilling              PaymentMethod  MonthlyCharges TotalCharges  \\\n",
              "0              Yes           Electronic check           29.85        29.85   \n",
              "1               No               Mailed check           56.95       1889.5   \n",
              "2              Yes               Mailed check           53.85       108.15   \n",
              "3               No  Bank transfer (automatic)           42.30      1840.75   \n",
              "4              Yes           Electronic check           70.70       151.65   \n",
              "\n",
              "  Churn  \n",
              "0    No  \n",
              "1    No  \n",
              "2   Yes  \n",
              "3    No  \n",
              "4   Yes  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpXczXpuP9p3",
        "outputId": "f66f022e-e2e4-442c-d6bc-8c44e008843d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "gender               object\n",
              "SeniorCitizen         int64\n",
              "Partner              object\n",
              "Dependents           object\n",
              "tenure                int64\n",
              "PhoneService         object\n",
              "MultipleLines        object\n",
              "InternetService      object\n",
              "OnlineSecurity       object\n",
              "OnlineBackup         object\n",
              "DeviceProtection     object\n",
              "TechSupport          object\n",
              "StreamingTV          object\n",
              "StreamingMovies      object\n",
              "Contract             object\n",
              "PaperlessBilling     object\n",
              "PaymentMethod        object\n",
              "MonthlyCharges      float64\n",
              "TotalCharges         object\n",
              "Churn                object\n",
              "dtype: object"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlihBwtzQAof",
        "outputId": "b97dcc69-f716-4bcd-e9db-b47b3c7d1b79"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['29.85', '1889.5', '108.15', ..., '346.45', '306.6', '6844.5'],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.TotalCharges.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFrY16_ZQDqB",
        "outputId": "bfddfdc3-0417-4230-8274-e3d21b2e60fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 29.85,  56.95,  53.85, ...,  29.6 ,  74.4 , 105.65])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.MonthlyCharges.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inBs6fbxQGvO",
        "outputId": "27f7b128-29f5-430e-9ae1-0b9027978778"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       False\n",
              "1       False\n",
              "2       False\n",
              "3       False\n",
              "4       False\n",
              "        ...  \n",
              "7038    False\n",
              "7039    False\n",
              "7040    False\n",
              "7041    False\n",
              "7042    False\n",
              "Name: TotalCharges, Length: 7043, dtype: bool"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.to_numeric(df.TotalCharges, errors = 'coerce').isnull()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmwSLhcaQYGr",
        "outputId": "7b122a17-e315-4905-8834-db4f927df7c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       False\n",
              "1       False\n",
              "2       False\n",
              "3       False\n",
              "4       False\n",
              "        ...  \n",
              "7038    False\n",
              "7039    False\n",
              "7040    False\n",
              "7041    False\n",
              "7042    False\n",
              "Name: TotalCharges, Length: 7043, dtype: bool"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.to_numeric(df.TotalCharges, errors = 'ignore').isnull()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113
        },
        "id": "MepKraYwQs3M",
        "outputId": "dff30266-d13e-4a41-970b-fc1b964de7d3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>SeniorCitizen</th>\n",
              "      <th>Partner</th>\n",
              "      <th>Dependents</th>\n",
              "      <th>tenure</th>\n",
              "      <th>PhoneService</th>\n",
              "      <th>MultipleLines</th>\n",
              "      <th>InternetService</th>\n",
              "      <th>OnlineSecurity</th>\n",
              "      <th>OnlineBackup</th>\n",
              "      <th>DeviceProtection</th>\n",
              "      <th>TechSupport</th>\n",
              "      <th>StreamingTV</th>\n",
              "      <th>StreamingMovies</th>\n",
              "      <th>Contract</th>\n",
              "      <th>PaperlessBilling</th>\n",
              "      <th>PaymentMethod</th>\n",
              "      <th>MonthlyCharges</th>\n",
              "      <th>TotalCharges</th>\n",
              "      <th>Churn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [gender, SeniorCitizen, Partner, Dependents, tenure, PhoneService, MultipleLines, InternetService, OnlineSecurity, OnlineBackup, DeviceProtection, TechSupport, StreamingTV, StreamingMovies, Contract, PaperlessBilling, PaymentMethod, MonthlyCharges, TotalCharges, Churn]\n",
              "Index: []"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[pd.to_numeric(df.TotalCharges, errors = 'ignore').isnull()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "MX-dGu4_QxCO",
        "outputId": "2ed8cd5c-45c2-4928-f4e1-43348a385757"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>SeniorCitizen</th>\n",
              "      <th>Partner</th>\n",
              "      <th>Dependents</th>\n",
              "      <th>tenure</th>\n",
              "      <th>PhoneService</th>\n",
              "      <th>MultipleLines</th>\n",
              "      <th>InternetService</th>\n",
              "      <th>OnlineSecurity</th>\n",
              "      <th>OnlineBackup</th>\n",
              "      <th>DeviceProtection</th>\n",
              "      <th>TechSupport</th>\n",
              "      <th>StreamingTV</th>\n",
              "      <th>StreamingMovies</th>\n",
              "      <th>Contract</th>\n",
              "      <th>PaperlessBilling</th>\n",
              "      <th>PaymentMethod</th>\n",
              "      <th>MonthlyCharges</th>\n",
              "      <th>TotalCharges</th>\n",
              "      <th>Churn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>488</th>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Two year</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Bank transfer (automatic)</td>\n",
              "      <td>52.55</td>\n",
              "      <td></td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>753</th>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No internet service</td>\n",
              "      <td>No internet service</td>\n",
              "      <td>No internet service</td>\n",
              "      <td>No internet service</td>\n",
              "      <td>No internet service</td>\n",
              "      <td>No internet service</td>\n",
              "      <td>Two year</td>\n",
              "      <td>No</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>20.25</td>\n",
              "      <td></td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>936</th>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Two year</td>\n",
              "      <td>No</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>80.85</td>\n",
              "      <td></td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1082</th>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No internet service</td>\n",
              "      <td>No internet service</td>\n",
              "      <td>No internet service</td>\n",
              "      <td>No internet service</td>\n",
              "      <td>No internet service</td>\n",
              "      <td>No internet service</td>\n",
              "      <td>Two year</td>\n",
              "      <td>No</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>25.75</td>\n",
              "      <td></td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1340</th>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Two year</td>\n",
              "      <td>No</td>\n",
              "      <td>Credit card (automatic)</td>\n",
              "      <td>56.05</td>\n",
              "      <td></td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3331</th>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No internet service</td>\n",
              "      <td>No internet service</td>\n",
              "      <td>No internet service</td>\n",
              "      <td>No internet service</td>\n",
              "      <td>No internet service</td>\n",
              "      <td>No internet service</td>\n",
              "      <td>Two year</td>\n",
              "      <td>No</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>19.85</td>\n",
              "      <td></td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3826</th>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No internet service</td>\n",
              "      <td>No internet service</td>\n",
              "      <td>No internet service</td>\n",
              "      <td>No internet service</td>\n",
              "      <td>No internet service</td>\n",
              "      <td>No internet service</td>\n",
              "      <td>Two year</td>\n",
              "      <td>No</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>25.35</td>\n",
              "      <td></td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4380</th>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No internet service</td>\n",
              "      <td>No internet service</td>\n",
              "      <td>No internet service</td>\n",
              "      <td>No internet service</td>\n",
              "      <td>No internet service</td>\n",
              "      <td>No internet service</td>\n",
              "      <td>Two year</td>\n",
              "      <td>No</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>20.00</td>\n",
              "      <td></td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5218</th>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No internet service</td>\n",
              "      <td>No internet service</td>\n",
              "      <td>No internet service</td>\n",
              "      <td>No internet service</td>\n",
              "      <td>No internet service</td>\n",
              "      <td>No internet service</td>\n",
              "      <td>One year</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>19.70</td>\n",
              "      <td></td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6670</th>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>DSL</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Two year</td>\n",
              "      <td>No</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>73.35</td>\n",
              "      <td></td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6754</th>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Two year</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Bank transfer (automatic)</td>\n",
              "      <td>61.90</td>\n",
              "      <td></td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
              "488   Female              0     Yes        Yes       0           No   \n",
              "753     Male              0      No        Yes       0          Yes   \n",
              "936   Female              0     Yes        Yes       0          Yes   \n",
              "1082    Male              0     Yes        Yes       0          Yes   \n",
              "1340  Female              0     Yes        Yes       0           No   \n",
              "3331    Male              0     Yes        Yes       0          Yes   \n",
              "3826    Male              0     Yes        Yes       0          Yes   \n",
              "4380  Female              0     Yes        Yes       0          Yes   \n",
              "5218    Male              0     Yes        Yes       0          Yes   \n",
              "6670  Female              0     Yes        Yes       0          Yes   \n",
              "6754    Male              0      No        Yes       0          Yes   \n",
              "\n",
              "         MultipleLines InternetService       OnlineSecurity  \\\n",
              "488   No phone service             DSL                  Yes   \n",
              "753                 No              No  No internet service   \n",
              "936                 No             DSL                  Yes   \n",
              "1082               Yes              No  No internet service   \n",
              "1340  No phone service             DSL                  Yes   \n",
              "3331                No              No  No internet service   \n",
              "3826               Yes              No  No internet service   \n",
              "4380                No              No  No internet service   \n",
              "5218                No              No  No internet service   \n",
              "6670               Yes             DSL                   No   \n",
              "6754               Yes             DSL                  Yes   \n",
              "\n",
              "             OnlineBackup     DeviceProtection          TechSupport  \\\n",
              "488                    No                  Yes                  Yes   \n",
              "753   No internet service  No internet service  No internet service   \n",
              "936                   Yes                  Yes                   No   \n",
              "1082  No internet service  No internet service  No internet service   \n",
              "1340                  Yes                  Yes                  Yes   \n",
              "3331  No internet service  No internet service  No internet service   \n",
              "3826  No internet service  No internet service  No internet service   \n",
              "4380  No internet service  No internet service  No internet service   \n",
              "5218  No internet service  No internet service  No internet service   \n",
              "6670                  Yes                  Yes                  Yes   \n",
              "6754                  Yes                   No                  Yes   \n",
              "\n",
              "              StreamingTV      StreamingMovies  Contract PaperlessBilling  \\\n",
              "488                   Yes                   No  Two year              Yes   \n",
              "753   No internet service  No internet service  Two year               No   \n",
              "936                   Yes                  Yes  Two year               No   \n",
              "1082  No internet service  No internet service  Two year               No   \n",
              "1340                  Yes                   No  Two year               No   \n",
              "3331  No internet service  No internet service  Two year               No   \n",
              "3826  No internet service  No internet service  Two year               No   \n",
              "4380  No internet service  No internet service  Two year               No   \n",
              "5218  No internet service  No internet service  One year              Yes   \n",
              "6670                  Yes                   No  Two year               No   \n",
              "6754                   No                   No  Two year              Yes   \n",
              "\n",
              "                  PaymentMethod  MonthlyCharges TotalCharges Churn  \n",
              "488   Bank transfer (automatic)           52.55                 No  \n",
              "753                Mailed check           20.25                 No  \n",
              "936                Mailed check           80.85                 No  \n",
              "1082               Mailed check           25.75                 No  \n",
              "1340    Credit card (automatic)           56.05                 No  \n",
              "3331               Mailed check           19.85                 No  \n",
              "3826               Mailed check           25.35                 No  \n",
              "4380               Mailed check           20.00                 No  \n",
              "5218               Mailed check           19.70                 No  \n",
              "6670               Mailed check           73.35                 No  \n",
              "6754  Bank transfer (automatic)           61.90                 No  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[pd.to_numeric(df.TotalCharges, errors = 'coerce').isnull()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bjQgy6JQ3MV",
        "outputId": "3a344d4b-55c4-4f41-94df-33fe991b62de"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(11, 20)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[pd.to_numeric(df.TotalCharges, errors = 'coerce').isnull()].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mL3AalNWRKo1"
      },
      "source": [
        "## Removing rows with no data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "iPU76rU1Q_ln"
      },
      "outputs": [],
      "source": [
        "df1 = df[df.TotalCharges != ' ']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XE7SO04WRXum",
        "outputId": "33ca457e-7daf-4c89-d55a-c0a5ab790ef9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7043, 20)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEB2nUGTRZSt",
        "outputId": "867aa98b-cb06-4619-d062-e289f3772787"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7032, 20)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koo-He5lRgV1",
        "outputId": "47c4b865-f8f1-4fa2-bf6c-673a717296eb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "gender               object\n",
              "SeniorCitizen         int64\n",
              "Partner              object\n",
              "Dependents           object\n",
              "tenure                int64\n",
              "PhoneService         object\n",
              "MultipleLines        object\n",
              "InternetService      object\n",
              "OnlineSecurity       object\n",
              "OnlineBackup         object\n",
              "DeviceProtection     object\n",
              "TechSupport          object\n",
              "StreamingTV          object\n",
              "StreamingMovies      object\n",
              "Contract             object\n",
              "PaperlessBilling     object\n",
              "PaymentMethod        object\n",
              "MonthlyCharges      float64\n",
              "TotalCharges         object\n",
              "Churn                object\n",
              "dtype: object"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7mTja2_RoX0",
        "outputId": "9d24bf13-9354-4fef-f305-a46e3b11dea2"
      },
      "outputs": [],
      "source": [
        "df1.TotalCharges = pd.to_numeric(df1.TotalCharges)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDO0SJHuR4Ch",
        "outputId": "e999dd3a-ece4-4c97-fb1a-d697bba86874"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "gender               object\n",
              "SeniorCitizen         int64\n",
              "Partner              object\n",
              "Dependents           object\n",
              "tenure                int64\n",
              "PhoneService         object\n",
              "MultipleLines        object\n",
              "InternetService      object\n",
              "OnlineSecurity       object\n",
              "OnlineBackup         object\n",
              "DeviceProtection     object\n",
              "TechSupport          object\n",
              "StreamingTV          object\n",
              "StreamingMovies      object\n",
              "Contract             object\n",
              "PaperlessBilling     object\n",
              "PaymentMethod        object\n",
              "MonthlyCharges      float64\n",
              "TotalCharges        float64\n",
              "Churn                object\n",
              "dtype: object"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4Ymdaw7SLJi"
      },
      "source": [
        "## Visualizing the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "NoYmrd9RR6JN",
        "outputId": "673119ff-ebf5-4e99-b7fb-5b86444828eb"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "tenure_churn_no = df1[df1.Churn == 'No'].tenure\n",
        "tenure_churn_yes = df1[df1.Churn == 'Yes'].tenure\n",
        "\n",
        "plt.xlabel('tenure')\n",
        "plt.ylabel('No. of Customers')\n",
        "plt.title(\"Customer Churn Prediction Visualization\")\n",
        "\n",
        "plt.hist([tenure_churn_no, tenure_churn_yes], rwidth = 0.9, color = ['red', 'green'], label = ['Churn - Yes', 'Churn - No'])\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "MK19T1mrTMzN",
        "outputId": "9de62038-238a-41ac-c164-4d70378b5e12"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "monthly_churn_no = df1[df1.Churn == 'No'].MonthlyCharges\n",
        "monthly_churn_yes = df1[df1.Churn == 'Yes'].MonthlyCharges\n",
        "\n",
        "plt.xlabel('MonthlyCharges')\n",
        "plt.ylabel('No. of Customers')\n",
        "plt.title(\"Customer Churn Prediction Visualization\")\n",
        "\n",
        "plt.hist([monthly_churn_no, monthly_churn_yes], rwidth = 0.9, color = ['red', 'green'], label = ['Churn - Yes', 'Churn - No'])\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25JdchgOXWvc"
      },
      "source": [
        "## getting the unique values from every column of the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZt-OclHTrgF",
        "outputId": "27fa9039-e713-42df-e735-62fbc0be1bff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Female', 'Male'], dtype=object)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1.gender.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hw6Bs5v7Xkw2",
        "outputId": "3186f331-7295-44e2-824b-74b5161bf35d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Female', 'Male'], dtype=object)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1['gender'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "e39MzR1CXpfn"
      },
      "outputs": [],
      "source": [
        "def unique_values(df):\n",
        "  for i in df:\n",
        "    if df[i].dtypes == 'object':\n",
        "      print(f'{i} : {df[i].unique()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLPuBmcpYDty",
        "outputId": "93de1183-f66a-4b87-e7c8-f3e2bdee3494"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gender : ['Female' 'Male']\n",
            "Partner : ['Yes' 'No']\n",
            "Dependents : ['No' 'Yes']\n",
            "PhoneService : ['No' 'Yes']\n",
            "MultipleLines : ['No phone service' 'No' 'Yes']\n",
            "InternetService : ['DSL' 'Fiber optic' 'No']\n",
            "OnlineSecurity : ['No' 'Yes' 'No internet service']\n",
            "OnlineBackup : ['Yes' 'No' 'No internet service']\n",
            "DeviceProtection : ['No' 'Yes' 'No internet service']\n",
            "TechSupport : ['No' 'Yes' 'No internet service']\n",
            "StreamingTV : ['No' 'Yes' 'No internet service']\n",
            "StreamingMovies : ['No' 'Yes' 'No internet service']\n",
            "Contract : ['Month-to-month' 'One year' 'Two year']\n",
            "PaperlessBilling : ['Yes' 'No']\n",
            "PaymentMethod : ['Electronic check' 'Mailed check' 'Bank transfer (automatic)'\n",
            " 'Credit card (automatic)']\n",
            "Churn : ['No' 'Yes']\n"
          ]
        }
      ],
      "source": [
        "unique_values(df1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-08V6Y8YQqQ"
      },
      "source": [
        "## we can convert :\n",
        "### No phone service -> No\n",
        "### No internet service -> No"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hl2bUadaYKNM",
        "outputId": "747c9f9c-3d82-4d9e-ddbb-6ab18041b7ec"
      },
      "outputs": [],
      "source": [
        "df1.replace('No internet service', 'No', inplace = True)\n",
        "df1.replace('No phone service', 'No', inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJbolLSFY04e",
        "outputId": "fb32f63a-b2f4-410d-9c74-2a42caeccbe4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gender : ['Female' 'Male']\n",
            "Partner : ['Yes' 'No']\n",
            "Dependents : ['No' 'Yes']\n",
            "PhoneService : ['No' 'Yes']\n",
            "MultipleLines : ['No' 'Yes']\n",
            "InternetService : ['DSL' 'Fiber optic' 'No']\n",
            "OnlineSecurity : ['No' 'Yes']\n",
            "OnlineBackup : ['Yes' 'No']\n",
            "DeviceProtection : ['No' 'Yes']\n",
            "TechSupport : ['No' 'Yes']\n",
            "StreamingTV : ['No' 'Yes']\n",
            "StreamingMovies : ['No' 'Yes']\n",
            "Contract : ['Month-to-month' 'One year' 'Two year']\n",
            "PaperlessBilling : ['Yes' 'No']\n",
            "PaymentMethod : ['Electronic check' 'Mailed check' 'Bank transfer (automatic)'\n",
            " 'Credit card (automatic)']\n",
            "Churn : ['No' 'Yes']\n"
          ]
        }
      ],
      "source": [
        "unique_values(df1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMmT1B_NY3rK",
        "outputId": "20e5572f-60e8-44f9-cb21-d97125e8ae5c"
      },
      "outputs": [],
      "source": [
        "yes_no_columns = ['Dependents','PhoneService','MultipleLines','OnlineSecurity','OnlineBackup', 'Partner',\n",
        "                  'DeviceProtection','TechSupport','StreamingTV','StreamingMovies','PaperlessBilling','Churn']\n",
        "\n",
        "for col in yes_no_columns:\n",
        "  df1[col].replace({'Yes': 1,'No': 0},inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ppglJlhfQLn",
        "outputId": "6b5a5efc-67bf-4760-f255-5a5bdc8280b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "gender                int64\n",
              "SeniorCitizen         int64\n",
              "Partner               int64\n",
              "Dependents            int64\n",
              "tenure                int64\n",
              "PhoneService          int64\n",
              "MultipleLines         int64\n",
              "InternetService      object\n",
              "OnlineSecurity        int64\n",
              "OnlineBackup          int64\n",
              "DeviceProtection      int64\n",
              "TechSupport           int64\n",
              "StreamingTV           int64\n",
              "StreamingMovies       int64\n",
              "Contract             object\n",
              "PaperlessBilling      int64\n",
              "PaymentMethod        object\n",
              "MonthlyCharges      float64\n",
              "TotalCharges        float64\n",
              "Churn                 int64\n",
              "dtype: object"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUxxBx6hgMqU",
        "outputId": "942c7273-4fcc-4443-94c0-4ce4b3110b28"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 1, 0, 0])"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1['Dependents'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mLSMjGXgYM3",
        "outputId": "74dc8161-7ecb-4442-a20e-80ba69b7d309"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "InternetService : ['DSL' 'Fiber optic' 'No']\n",
            "Contract : ['Month-to-month' 'One year' 'Two year']\n",
            "PaymentMethod : ['Electronic check' 'Mailed check' 'Bank transfer (automatic)'\n",
            " 'Credit card (automatic)']\n"
          ]
        }
      ],
      "source": [
        "unique_values(df1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVSpBKHDgoQW",
        "outputId": "6d16485a-3d23-471c-cfb9-1806bfd9ad49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gender : [1 0]\n",
            "SeniorCitizen : [0 1]\n",
            "Partner : [1 0]\n",
            "Dependents : [0 1]\n",
            "tenure : [ 1 34  2 45  8 22 10 28 62 13 16 58 49 25 69 52 71 21 12 30 47 72 17 27\n",
            "  5 46 11 70 63 43 15 60 18 66  9  3 31 50 64 56  7 42 35 48 29 65 38 68\n",
            " 32 55 37 36 41  6  4 33 67 23 57 61 14 20 53 40 59 24 44 19 54 51 26 39]\n",
            "PhoneService : [0 1]\n",
            "MultipleLines : [0 1]\n",
            "InternetService : ['DSL' 'Fiber optic' 'No']\n",
            "OnlineSecurity : [0 1]\n",
            "OnlineBackup : [1 0]\n",
            "DeviceProtection : [0 1]\n",
            "TechSupport : [0 1]\n",
            "StreamingTV : [0 1]\n",
            "StreamingMovies : [0 1]\n",
            "Contract : ['Month-to-month' 'One year' 'Two year']\n",
            "PaperlessBilling : [1 0]\n",
            "PaymentMethod : ['Electronic check' 'Mailed check' 'Bank transfer (automatic)'\n",
            " 'Credit card (automatic)']\n",
            "MonthlyCharges : [29.85 56.95 53.85 ... 63.1  44.2  78.7 ]\n",
            "TotalCharges : [  29.85 1889.5   108.15 ...  346.45  306.6  6844.5 ]\n",
            "Churn : [0 1]\n"
          ]
        }
      ],
      "source": [
        "for i in df1:\n",
        "  print(f'{i} : {df1[i].unique()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJJ-GyRuiGZQ",
        "outputId": "90488dfb-1eb0-4065-b564-352cd9ee0883"
      },
      "outputs": [],
      "source": [
        "df1['gender'].replace({'Female' : 1, 'Male': 0}, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8flS47uiUmY",
        "outputId": "827e865b-f335-4bbc-84f4-eacd639066ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gender : [1 0]\n",
            "SeniorCitizen : [0 1]\n",
            "Partner : [1 0]\n",
            "Dependents : [0 1]\n",
            "tenure : [ 1 34  2 45  8 22 10 28 62 13 16 58 49 25 69 52 71 21 12 30 47 72 17 27\n",
            "  5 46 11 70 63 43 15 60 18 66  9  3 31 50 64 56  7 42 35 48 29 65 38 68\n",
            " 32 55 37 36 41  6  4 33 67 23 57 61 14 20 53 40 59 24 44 19 54 51 26 39]\n",
            "PhoneService : [0 1]\n",
            "MultipleLines : [0 1]\n",
            "InternetService : ['DSL' 'Fiber optic' 'No']\n",
            "OnlineSecurity : [0 1]\n",
            "OnlineBackup : [1 0]\n",
            "DeviceProtection : [0 1]\n",
            "TechSupport : [0 1]\n",
            "StreamingTV : [0 1]\n",
            "StreamingMovies : [0 1]\n",
            "Contract : ['Month-to-month' 'One year' 'Two year']\n",
            "PaperlessBilling : [1 0]\n",
            "PaymentMethod : ['Electronic check' 'Mailed check' 'Bank transfer (automatic)'\n",
            " 'Credit card (automatic)']\n",
            "MonthlyCharges : [29.85 56.95 53.85 ... 63.1  44.2  78.7 ]\n",
            "TotalCharges : [  29.85 1889.5   108.15 ...  346.45  306.6  6844.5 ]\n",
            "Churn : [0 1]\n"
          ]
        }
      ],
      "source": [
        "for i in df1:\n",
        "  print(f'{i} : {df1[i].unique()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yN3hRwgsip-e"
      },
      "source": [
        "## One Hot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8dAupUUiftK",
        "outputId": "e6909dd6-ca52-4329-f6ce-d614ea4248ea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'tenure',\n",
              "       'PhoneService', 'MultipleLines', 'OnlineSecurity', 'OnlineBackup',\n",
              "       'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies',\n",
              "       'PaperlessBilling', 'MonthlyCharges', 'TotalCharges', 'Churn',\n",
              "       'InternetService_DSL', 'InternetService_Fiber optic',\n",
              "       'InternetService_No', 'Contract_Month-to-month', 'Contract_One year',\n",
              "       'Contract_Two year', 'PaymentMethod_Bank transfer (automatic)',\n",
              "       'PaymentMethod_Credit card (automatic)',\n",
              "       'PaymentMethod_Electronic check', 'PaymentMethod_Mailed check'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2 = pd.get_dummies(data = df1, columns = ['InternetService','Contract','PaymentMethod'])\n",
        "df2.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "uJahVVxWi38A"
      },
      "outputs": [],
      "source": [
        "scaling_cols = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "df2[scaling_cols] = scaler.fit_transform(df2[scaling_cols])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiF9tEdqjmKM",
        "outputId": "0c68e74c-1ef4-444a-c6be-a8749e1ac6c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gender: [1 0]\n",
            "SeniorCitizen: [0 1]\n",
            "Partner: [1 0]\n",
            "Dependents: [0 1]\n",
            "tenure: [0.         0.46478873 0.01408451 0.61971831 0.09859155 0.29577465\n",
            " 0.12676056 0.38028169 0.85915493 0.16901408 0.21126761 0.8028169\n",
            " 0.67605634 0.33802817 0.95774648 0.71830986 0.98591549 0.28169014\n",
            " 0.15492958 0.4084507  0.64788732 1.         0.22535211 0.36619718\n",
            " 0.05633803 0.63380282 0.14084507 0.97183099 0.87323944 0.5915493\n",
            " 0.1971831  0.83098592 0.23943662 0.91549296 0.11267606 0.02816901\n",
            " 0.42253521 0.69014085 0.88732394 0.77464789 0.08450704 0.57746479\n",
            " 0.47887324 0.66197183 0.3943662  0.90140845 0.52112676 0.94366197\n",
            " 0.43661972 0.76056338 0.50704225 0.49295775 0.56338028 0.07042254\n",
            " 0.04225352 0.45070423 0.92957746 0.30985915 0.78873239 0.84507042\n",
            " 0.18309859 0.26760563 0.73239437 0.54929577 0.81690141 0.32394366\n",
            " 0.6056338  0.25352113 0.74647887 0.70422535 0.35211268 0.53521127]\n",
            "PhoneService: [0 1]\n",
            "MultipleLines: [0 1]\n",
            "OnlineSecurity: [0 1]\n",
            "OnlineBackup: [1 0]\n",
            "DeviceProtection: [0 1]\n",
            "TechSupport: [0 1]\n",
            "StreamingTV: [0 1]\n",
            "StreamingMovies: [0 1]\n",
            "PaperlessBilling: [1 0]\n",
            "MonthlyCharges: [0.11542289 0.38507463 0.35422886 ... 0.44626866 0.25820896 0.60149254]\n",
            "TotalCharges: [0.0012751  0.21586661 0.01031041 ... 0.03780868 0.03321025 0.78764136]\n",
            "Churn: [0 1]\n",
            "InternetService_DSL: [1 0]\n",
            "InternetService_Fiber optic: [0 1]\n",
            "InternetService_No: [0 1]\n",
            "Contract_Month-to-month: [1 0]\n",
            "Contract_One year: [0 1]\n",
            "Contract_Two year: [0 1]\n",
            "PaymentMethod_Bank transfer (automatic): [0 1]\n",
            "PaymentMethod_Credit card (automatic): [0 1]\n",
            "PaymentMethod_Electronic check: [1 0]\n",
            "PaymentMethod_Mailed check: [0 1]\n"
          ]
        }
      ],
      "source": [
        "for col in df2:\n",
        "    print(f'{col}: {df2[col].unique()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9wI4GFajvJP"
      },
      "source": [
        "## Train Test Splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "IZr5MPy3joyE"
      },
      "outputs": [],
      "source": [
        "x = df2.drop('Churn', axis = 'columns')\n",
        "y = df2['Churn']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJqv3HH7kyN6"
      },
      "source": [
        "## Building the ANN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L81V_9LVkKYm",
        "outputId": "2ed091e7-0d55-4f7a-be7f-ff7502737dbe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-02-01 14:33:24.843806: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
            "2022-02-01 14:33:25.017791: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "176/176 [==============================] - 2s 7ms/step - loss: 0.4570 - accuracy: 0.7762\n",
            "Epoch 2/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4210 - accuracy: 0.7996\n",
            "Epoch 3/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.4133 - accuracy: 0.8028\n",
            "Epoch 4/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4091 - accuracy: 0.8108\n",
            "Epoch 5/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.4058 - accuracy: 0.8066\n",
            "Epoch 6/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4020 - accuracy: 0.8096\n",
            "Epoch 7/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.3943 - accuracy: 0.8121\n",
            "Epoch 8/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.3904 - accuracy: 0.8181\n",
            "Epoch 9/500\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.3831 - accuracy: 0.8180\n",
            "Epoch 10/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3778 - accuracy: 0.8212\n",
            "Epoch 11/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3719 - accuracy: 0.8245\n",
            "Epoch 12/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3653 - accuracy: 0.8247\n",
            "Epoch 13/500\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.3536 - accuracy: 0.8329\n",
            "Epoch 14/500\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.3435 - accuracy: 0.8375\n",
            "Epoch 15/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.3320 - accuracy: 0.8411\n",
            "Epoch 16/500\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.3207 - accuracy: 0.8482\n",
            "Epoch 17/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.3103 - accuracy: 0.8560\n",
            "Epoch 18/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.3022 - accuracy: 0.8581\n",
            "Epoch 19/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.2875 - accuracy: 0.8670\n",
            "Epoch 20/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.2793 - accuracy: 0.8711\n",
            "Epoch 21/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.2667 - accuracy: 0.8779\n",
            "Epoch 22/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.2549 - accuracy: 0.8876\n",
            "Epoch 23/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.2481 - accuracy: 0.8869\n",
            "Epoch 24/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.2339 - accuracy: 0.8921\n",
            "Epoch 25/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.2227 - accuracy: 0.9022\n",
            "Epoch 26/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.2147 - accuracy: 0.9029\n",
            "Epoch 27/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.2051 - accuracy: 0.9081\n",
            "Epoch 28/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.2017 - accuracy: 0.9109\n",
            "Epoch 29/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1945 - accuracy: 0.9132\n",
            "Epoch 30/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.1813 - accuracy: 0.9179\n",
            "Epoch 31/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.1835 - accuracy: 0.9191\n",
            "Epoch 32/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1686 - accuracy: 0.9253\n",
            "Epoch 33/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1694 - accuracy: 0.9236\n",
            "Epoch 34/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1699 - accuracy: 0.9262\n",
            "Epoch 35/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1586 - accuracy: 0.9292\n",
            "Epoch 36/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1634 - accuracy: 0.9262\n",
            "Epoch 37/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1548 - accuracy: 0.9284\n",
            "Epoch 38/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1474 - accuracy: 0.9324\n",
            "Epoch 39/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1462 - accuracy: 0.9312\n",
            "Epoch 40/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1445 - accuracy: 0.9335\n",
            "Epoch 41/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1466 - accuracy: 0.9319\n",
            "Epoch 42/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1447 - accuracy: 0.9337\n",
            "Epoch 43/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1390 - accuracy: 0.9333\n",
            "Epoch 44/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1615 - accuracy: 0.9282\n",
            "Epoch 45/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1328 - accuracy: 0.9390\n",
            "Epoch 46/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1330 - accuracy: 0.9358\n",
            "Epoch 47/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1273 - accuracy: 0.9396\n",
            "Epoch 48/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1214 - accuracy: 0.9415\n",
            "Epoch 49/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1307 - accuracy: 0.9353\n",
            "Epoch 50/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1297 - accuracy: 0.9396\n",
            "Epoch 51/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.1276 - accuracy: 0.9397\n",
            "Epoch 52/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1246 - accuracy: 0.9390\n",
            "Epoch 53/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1171 - accuracy: 0.9424\n",
            "Epoch 54/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1212 - accuracy: 0.9415\n",
            "Epoch 55/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1276 - accuracy: 0.9396\n",
            "Epoch 56/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1316 - accuracy: 0.9374\n",
            "Epoch 57/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1170 - accuracy: 0.9438\n",
            "Epoch 58/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1210 - accuracy: 0.9420\n",
            "Epoch 59/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1185 - accuracy: 0.9419\n",
            "Epoch 60/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1232 - accuracy: 0.9406\n",
            "Epoch 61/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1163 - accuracy: 0.9426\n",
            "Epoch 62/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.1197 - accuracy: 0.9417\n",
            "Epoch 63/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1215 - accuracy: 0.9385\n",
            "Epoch 64/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1180 - accuracy: 0.9417\n",
            "Epoch 65/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1120 - accuracy: 0.9442\n",
            "Epoch 66/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1120 - accuracy: 0.9444\n",
            "Epoch 67/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1105 - accuracy: 0.9444\n",
            "Epoch 68/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1054 - accuracy: 0.9458\n",
            "Epoch 69/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1063 - accuracy: 0.9461\n",
            "Epoch 70/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1078 - accuracy: 0.9470\n",
            "Epoch 71/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1113 - accuracy: 0.9428\n",
            "Epoch 72/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1303 - accuracy: 0.9371\n",
            "Epoch 73/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1224 - accuracy: 0.9394\n",
            "Epoch 74/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1165 - accuracy: 0.9447\n",
            "Epoch 75/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1128 - accuracy: 0.9452\n",
            "Epoch 76/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1059 - accuracy: 0.9468\n",
            "Epoch 77/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1033 - accuracy: 0.9492\n",
            "Epoch 78/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1038 - accuracy: 0.9484\n",
            "Epoch 79/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1078 - accuracy: 0.9476\n",
            "Epoch 80/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1164 - accuracy: 0.9426\n",
            "Epoch 81/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1078 - accuracy: 0.9440\n",
            "Epoch 82/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1012 - accuracy: 0.9465\n",
            "Epoch 83/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1036 - accuracy: 0.9481\n",
            "Epoch 84/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1181 - accuracy: 0.9460\n",
            "Epoch 85/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1188 - accuracy: 0.9429\n",
            "Epoch 86/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1053 - accuracy: 0.9483\n",
            "Epoch 87/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1115 - accuracy: 0.9422\n",
            "Epoch 88/500\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.1022 - accuracy: 0.9506\n",
            "Epoch 89/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0987 - accuracy: 0.9499\n",
            "Epoch 90/500\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.1034 - accuracy: 0.9477\n",
            "Epoch 91/500\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.1023 - accuracy: 0.9509\n",
            "Epoch 92/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0924 - accuracy: 0.9509\n",
            "Epoch 93/500\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0951 - accuracy: 0.9508\n",
            "Epoch 94/500\n",
            "176/176 [==============================] - 1s 9ms/step - loss: 0.0945 - accuracy: 0.9492\n",
            "Epoch 95/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1011 - accuracy: 0.9500\n",
            "Epoch 96/500\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.1235 - accuracy: 0.9419\n",
            "Epoch 97/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.1080 - accuracy: 0.9436\n",
            "Epoch 98/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0993 - accuracy: 0.9499\n",
            "Epoch 99/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1024 - accuracy: 0.9476\n",
            "Epoch 100/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0927 - accuracy: 0.9516\n",
            "Epoch 101/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0949 - accuracy: 0.9522\n",
            "Epoch 102/500\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0992 - accuracy: 0.9490\n",
            "Epoch 103/500\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.1043 - accuracy: 0.9492\n",
            "Epoch 104/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1007 - accuracy: 0.9520\n",
            "Epoch 105/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1066 - accuracy: 0.9486\n",
            "Epoch 106/500\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.1001 - accuracy: 0.9490\n",
            "Epoch 107/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0972 - accuracy: 0.9515\n",
            "Epoch 108/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0952 - accuracy: 0.9529\n",
            "Epoch 109/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0922 - accuracy: 0.9540\n",
            "Epoch 110/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0887 - accuracy: 0.9536\n",
            "Epoch 111/500\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0889 - accuracy: 0.9531\n",
            "Epoch 112/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.1016 - accuracy: 0.9511\n",
            "Epoch 113/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0898 - accuracy: 0.9538\n",
            "Epoch 114/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1048 - accuracy: 0.9492\n",
            "Epoch 115/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0968 - accuracy: 0.9499\n",
            "Epoch 116/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0940 - accuracy: 0.9534\n",
            "Epoch 117/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0925 - accuracy: 0.9529\n",
            "Epoch 118/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0951 - accuracy: 0.9520\n",
            "Epoch 119/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.1248 - accuracy: 0.9431\n",
            "Epoch 120/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.1055 - accuracy: 0.9516\n",
            "Epoch 121/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0952 - accuracy: 0.9529\n",
            "Epoch 122/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0871 - accuracy: 0.9554\n",
            "Epoch 123/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0860 - accuracy: 0.9547\n",
            "Epoch 124/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0842 - accuracy: 0.9563\n",
            "Epoch 125/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0889 - accuracy: 0.9547\n",
            "Epoch 126/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0847 - accuracy: 0.9550\n",
            "Epoch 127/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0872 - accuracy: 0.9552\n",
            "Epoch 128/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0997 - accuracy: 0.9506\n",
            "Epoch 129/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0942 - accuracy: 0.9527\n",
            "Epoch 130/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0904 - accuracy: 0.9532\n",
            "Epoch 131/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0914 - accuracy: 0.9541\n",
            "Epoch 132/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.1077 - accuracy: 0.9477\n",
            "Epoch 133/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.1043 - accuracy: 0.9525\n",
            "Epoch 134/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.1003 - accuracy: 0.9504\n",
            "Epoch 135/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0876 - accuracy: 0.9566\n",
            "Epoch 136/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0831 - accuracy: 0.9584\n",
            "Epoch 137/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0915 - accuracy: 0.9561\n",
            "Epoch 138/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0897 - accuracy: 0.9527\n",
            "Epoch 139/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0830 - accuracy: 0.9570\n",
            "Epoch 140/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0823 - accuracy: 0.9568\n",
            "Epoch 141/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0868 - accuracy: 0.9572\n",
            "Epoch 142/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0983 - accuracy: 0.9504\n",
            "Epoch 143/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.1079 - accuracy: 0.9518\n",
            "Epoch 144/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0881 - accuracy: 0.9538\n",
            "Epoch 145/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.1057 - accuracy: 0.9470\n",
            "Epoch 146/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0977 - accuracy: 0.9538\n",
            "Epoch 147/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0900 - accuracy: 0.9541\n",
            "Epoch 148/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0916 - accuracy: 0.9566\n",
            "Epoch 149/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0830 - accuracy: 0.9563\n",
            "Epoch 150/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0846 - accuracy: 0.9582\n",
            "Epoch 151/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0939 - accuracy: 0.9527\n",
            "Epoch 152/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0911 - accuracy: 0.9538\n",
            "Epoch 153/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0932 - accuracy: 0.9540\n",
            "Epoch 154/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0813 - accuracy: 0.9572\n",
            "Epoch 155/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0798 - accuracy: 0.9568\n",
            "Epoch 156/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0813 - accuracy: 0.9582\n",
            "Epoch 157/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0842 - accuracy: 0.9589\n",
            "Epoch 158/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0785 - accuracy: 0.9577\n",
            "Epoch 159/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0831 - accuracy: 0.9566\n",
            "Epoch 160/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0846 - accuracy: 0.9559\n",
            "Epoch 161/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0892 - accuracy: 0.9538\n",
            "Epoch 162/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0979 - accuracy: 0.9524\n",
            "Epoch 163/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.1003 - accuracy: 0.9497\n",
            "Epoch 164/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0866 - accuracy: 0.9554\n",
            "Epoch 165/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0822 - accuracy: 0.9584\n",
            "Epoch 166/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0818 - accuracy: 0.9584\n",
            "Epoch 167/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0802 - accuracy: 0.9573\n",
            "Epoch 168/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0824 - accuracy: 0.9559\n",
            "Epoch 169/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0862 - accuracy: 0.9580\n",
            "Epoch 170/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0859 - accuracy: 0.9557\n",
            "Epoch 171/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0964 - accuracy: 0.9525\n",
            "Epoch 172/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0929 - accuracy: 0.9543\n",
            "Epoch 173/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0794 - accuracy: 0.9577\n",
            "Epoch 174/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0799 - accuracy: 0.9582\n",
            "Epoch 175/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0810 - accuracy: 0.9564\n",
            "Epoch 176/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0796 - accuracy: 0.9586\n",
            "Epoch 177/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0835 - accuracy: 0.9570\n",
            "Epoch 178/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0932 - accuracy: 0.9541\n",
            "Epoch 179/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0974 - accuracy: 0.9531\n",
            "Epoch 180/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0970 - accuracy: 0.9534\n",
            "Epoch 181/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0939 - accuracy: 0.9548\n",
            "Epoch 182/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0812 - accuracy: 0.9591\n",
            "Epoch 183/500\n",
            "176/176 [==============================] - 921s 5s/step - loss: 0.0777 - accuracy: 0.9600\n",
            "Epoch 184/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0771 - accuracy: 0.9612\n",
            "Epoch 185/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0792 - accuracy: 0.9593\n",
            "Epoch 186/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0750 - accuracy: 0.9593\n",
            "Epoch 187/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0743 - accuracy: 0.9598\n",
            "Epoch 188/500\n",
            "176/176 [==============================] - 1035s 6s/step - loss: 0.0800 - accuracy: 0.9595\n",
            "Epoch 189/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0774 - accuracy: 0.9589\n",
            "Epoch 190/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0802 - accuracy: 0.9607\n",
            "Epoch 191/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0877 - accuracy: 0.9575\n",
            "Epoch 192/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0886 - accuracy: 0.9568\n",
            "Epoch 193/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0928 - accuracy: 0.9557\n",
            "Epoch 194/500\n",
            "176/176 [==============================] - 1006s 6s/step - loss: 0.0986 - accuracy: 0.9529\n",
            "Epoch 195/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0908 - accuracy: 0.9552\n",
            "Epoch 196/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0772 - accuracy: 0.9593\n",
            "Epoch 197/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0743 - accuracy: 0.9604\n",
            "Epoch 198/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0734 - accuracy: 0.9623\n",
            "Epoch 199/500\n",
            "176/176 [==============================] - 951s 5s/step - loss: 0.0750 - accuracy: 0.9604\n",
            "Epoch 200/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0766 - accuracy: 0.9614\n",
            "Epoch 201/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0751 - accuracy: 0.9609\n",
            "Epoch 202/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0780 - accuracy: 0.9612\n",
            "Epoch 203/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0944 - accuracy: 0.9541\n",
            "Epoch 204/500\n",
            "176/176 [==============================] - 957s 5s/step - loss: 0.0889 - accuracy: 0.9579\n",
            "Epoch 205/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0759 - accuracy: 0.9595\n",
            "Epoch 206/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0773 - accuracy: 0.9573\n",
            "Epoch 207/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0861 - accuracy: 0.9566\n",
            "Epoch 208/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0800 - accuracy: 0.9588\n",
            "Epoch 209/500\n",
            "176/176 [==============================] - 127s 725ms/step - loss: 0.0802 - accuracy: 0.9589\n",
            "Epoch 210/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0743 - accuracy: 0.9611\n",
            "Epoch 211/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0767 - accuracy: 0.9605\n",
            "Epoch 212/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0728 - accuracy: 0.9620\n",
            "Epoch 213/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0788 - accuracy: 0.9607\n",
            "Epoch 214/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0818 - accuracy: 0.9573\n",
            "Epoch 215/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0979 - accuracy: 0.9570\n",
            "Epoch 216/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0924 - accuracy: 0.9563\n",
            "Epoch 217/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0990 - accuracy: 0.9525\n",
            "Epoch 218/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0872 - accuracy: 0.9595\n",
            "Epoch 219/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0793 - accuracy: 0.9582\n",
            "Epoch 220/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0719 - accuracy: 0.9643\n",
            "Epoch 221/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0723 - accuracy: 0.9607\n",
            "Epoch 222/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0707 - accuracy: 0.9612\n",
            "Epoch 223/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0745 - accuracy: 0.9612\n",
            "Epoch 224/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0734 - accuracy: 0.9616\n",
            "Epoch 225/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0759 - accuracy: 0.9623\n",
            "Epoch 226/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0773 - accuracy: 0.9570\n",
            "Epoch 227/500\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0752 - accuracy: 0.9607\n",
            "Epoch 228/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0700 - accuracy: 0.9643\n",
            "Epoch 229/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1050 - accuracy: 0.9529\n",
            "Epoch 230/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0936 - accuracy: 0.9532\n",
            "Epoch 231/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0854 - accuracy: 0.9589\n",
            "Epoch 232/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0765 - accuracy: 0.9611\n",
            "Epoch 233/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0845 - accuracy: 0.9602\n",
            "Epoch 234/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0851 - accuracy: 0.9577\n",
            "Epoch 235/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0757 - accuracy: 0.9623\n",
            "Epoch 236/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0732 - accuracy: 0.9625\n",
            "Epoch 237/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0739 - accuracy: 0.9628\n",
            "Epoch 238/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0769 - accuracy: 0.9641\n",
            "Epoch 239/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0748 - accuracy: 0.9625\n",
            "Epoch 240/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0772 - accuracy: 0.9605\n",
            "Epoch 241/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0829 - accuracy: 0.9572\n",
            "Epoch 242/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0841 - accuracy: 0.9600\n",
            "Epoch 243/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0823 - accuracy: 0.9586\n",
            "Epoch 244/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0733 - accuracy: 0.9634\n",
            "Epoch 245/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0698 - accuracy: 0.9646\n",
            "Epoch 246/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0700 - accuracy: 0.9620\n",
            "Epoch 247/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0721 - accuracy: 0.9637\n",
            "Epoch 248/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0723 - accuracy: 0.9627\n",
            "Epoch 249/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0741 - accuracy: 0.9614\n",
            "Epoch 250/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0776 - accuracy: 0.9602\n",
            "Epoch 251/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0887 - accuracy: 0.9602\n",
            "Epoch 252/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0753 - accuracy: 0.9605\n",
            "Epoch 253/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0786 - accuracy: 0.9600\n",
            "Epoch 254/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0740 - accuracy: 0.9609\n",
            "Epoch 255/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.1162 - accuracy: 0.9520\n",
            "Epoch 256/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0822 - accuracy: 0.9604\n",
            "Epoch 257/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0757 - accuracy: 0.9611\n",
            "Epoch 258/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0711 - accuracy: 0.9644\n",
            "Epoch 259/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0696 - accuracy: 0.9639\n",
            "Epoch 260/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0683 - accuracy: 0.9627\n",
            "Epoch 261/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0687 - accuracy: 0.9621\n",
            "Epoch 262/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0678 - accuracy: 0.9636\n",
            "Epoch 263/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0691 - accuracy: 0.9641\n",
            "Epoch 264/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0715 - accuracy: 0.9612\n",
            "Epoch 265/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0718 - accuracy: 0.9625\n",
            "Epoch 266/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0767 - accuracy: 0.9605\n",
            "Epoch 267/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0806 - accuracy: 0.9591\n",
            "Epoch 268/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0786 - accuracy: 0.9593\n",
            "Epoch 269/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0845 - accuracy: 0.9598\n",
            "Epoch 270/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0840 - accuracy: 0.9586\n",
            "Epoch 271/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0712 - accuracy: 0.9637\n",
            "Epoch 272/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0707 - accuracy: 0.9648\n",
            "Epoch 273/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0712 - accuracy: 0.9621\n",
            "Epoch 274/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0680 - accuracy: 0.9637\n",
            "Epoch 275/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0694 - accuracy: 0.9630\n",
            "Epoch 276/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0708 - accuracy: 0.9630\n",
            "Epoch 277/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0951 - accuracy: 0.9548\n",
            "Epoch 278/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0865 - accuracy: 0.9589\n",
            "Epoch 279/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0735 - accuracy: 0.9618\n",
            "Epoch 280/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0711 - accuracy: 0.9644\n",
            "Epoch 281/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0678 - accuracy: 0.9650\n",
            "Epoch 282/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0724 - accuracy: 0.9616\n",
            "Epoch 283/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0775 - accuracy: 0.9611\n",
            "Epoch 284/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0772 - accuracy: 0.9591\n",
            "Epoch 285/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0721 - accuracy: 0.9607\n",
            "Epoch 286/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0674 - accuracy: 0.9650\n",
            "Epoch 287/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0708 - accuracy: 0.9620\n",
            "Epoch 288/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0858 - accuracy: 0.9602\n",
            "Epoch 289/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0775 - accuracy: 0.9639\n",
            "Epoch 290/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0756 - accuracy: 0.9641\n",
            "Epoch 291/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0691 - accuracy: 0.9639\n",
            "Epoch 292/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0697 - accuracy: 0.9630\n",
            "Epoch 293/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0717 - accuracy: 0.9643\n",
            "Epoch 294/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0668 - accuracy: 0.9646\n",
            "Epoch 295/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0716 - accuracy: 0.9639\n",
            "Epoch 296/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0760 - accuracy: 0.9628\n",
            "Epoch 297/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0705 - accuracy: 0.9628\n",
            "Epoch 298/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0773 - accuracy: 0.9621\n",
            "Epoch 299/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0829 - accuracy: 0.9593\n",
            "Epoch 300/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0923 - accuracy: 0.9564\n",
            "Epoch 301/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0789 - accuracy: 0.9612\n",
            "Epoch 302/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0683 - accuracy: 0.9644\n",
            "Epoch 303/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0654 - accuracy: 0.9662\n",
            "Epoch 304/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0658 - accuracy: 0.9648\n",
            "Epoch 305/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0684 - accuracy: 0.9646\n",
            "Epoch 306/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0649 - accuracy: 0.9655\n",
            "Epoch 307/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0646 - accuracy: 0.9669\n",
            "Epoch 308/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0675 - accuracy: 0.9653\n",
            "Epoch 309/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0709 - accuracy: 0.9643\n",
            "Epoch 310/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0774 - accuracy: 0.9627\n",
            "Epoch 311/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0810 - accuracy: 0.9612\n",
            "Epoch 312/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0760 - accuracy: 0.9620\n",
            "Epoch 313/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0801 - accuracy: 0.9604\n",
            "Epoch 314/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0989 - accuracy: 0.9579\n",
            "Epoch 315/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0715 - accuracy: 0.9646\n",
            "Epoch 316/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0673 - accuracy: 0.9657\n",
            "Epoch 317/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0662 - accuracy: 0.9646\n",
            "Epoch 318/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0649 - accuracy: 0.9650\n",
            "Epoch 319/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0679 - accuracy: 0.9628\n",
            "Epoch 320/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0669 - accuracy: 0.9644\n",
            "Epoch 321/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0661 - accuracy: 0.9662\n",
            "Epoch 322/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0671 - accuracy: 0.9648\n",
            "Epoch 323/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0753 - accuracy: 0.9623\n",
            "Epoch 324/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0804 - accuracy: 0.9609\n",
            "Epoch 325/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0792 - accuracy: 0.9627\n",
            "Epoch 326/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0788 - accuracy: 0.9630\n",
            "Epoch 327/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0692 - accuracy: 0.9628\n",
            "Epoch 328/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0664 - accuracy: 0.9653\n",
            "Epoch 329/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0673 - accuracy: 0.9652\n",
            "Epoch 330/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0670 - accuracy: 0.9657\n",
            "Epoch 331/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0840 - accuracy: 0.9596\n",
            "Epoch 332/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0706 - accuracy: 0.9632\n",
            "Epoch 333/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0677 - accuracy: 0.9650\n",
            "Epoch 334/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0688 - accuracy: 0.9623\n",
            "Epoch 335/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0674 - accuracy: 0.9646\n",
            "Epoch 336/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0717 - accuracy: 0.9616\n",
            "Epoch 337/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0676 - accuracy: 0.9652\n",
            "Epoch 338/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0659 - accuracy: 0.9657\n",
            "Epoch 339/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0658 - accuracy: 0.9657\n",
            "Epoch 340/500\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0673 - accuracy: 0.9648\n",
            "Epoch 341/500\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0640 - accuracy: 0.9653\n",
            "Epoch 342/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0718 - accuracy: 0.9625\n",
            "Epoch 343/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0962 - accuracy: 0.9579\n",
            "Epoch 344/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0817 - accuracy: 0.9609\n",
            "Epoch 345/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0667 - accuracy: 0.9666\n",
            "Epoch 346/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0652 - accuracy: 0.9659\n",
            "Epoch 347/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0672 - accuracy: 0.9618\n",
            "Epoch 348/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0646 - accuracy: 0.9653\n",
            "Epoch 349/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0653 - accuracy: 0.9643\n",
            "Epoch 350/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0658 - accuracy: 0.9675\n",
            "Epoch 351/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0674 - accuracy: 0.9637\n",
            "Epoch 352/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0679 - accuracy: 0.9652\n",
            "Epoch 353/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0811 - accuracy: 0.9609\n",
            "Epoch 354/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0714 - accuracy: 0.9632\n",
            "Epoch 355/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0760 - accuracy: 0.9630\n",
            "Epoch 356/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0707 - accuracy: 0.9652\n",
            "Epoch 357/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0632 - accuracy: 0.9680\n",
            "Epoch 358/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0686 - accuracy: 0.9648\n",
            "Epoch 359/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0650 - accuracy: 0.9659\n",
            "Epoch 360/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0645 - accuracy: 0.9657\n",
            "Epoch 361/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0727 - accuracy: 0.9621\n",
            "Epoch 362/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0704 - accuracy: 0.9634\n",
            "Epoch 363/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0691 - accuracy: 0.9650\n",
            "Epoch 364/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0780 - accuracy: 0.9602\n",
            "Epoch 365/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0626 - accuracy: 0.9675\n",
            "Epoch 366/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0652 - accuracy: 0.9668\n",
            "Epoch 367/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0671 - accuracy: 0.9659\n",
            "Epoch 368/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0739 - accuracy: 0.9655\n",
            "Epoch 369/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0821 - accuracy: 0.9614\n",
            "Epoch 370/500\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0800 - accuracy: 0.9607\n",
            "Epoch 371/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0702 - accuracy: 0.9641\n",
            "Epoch 372/500\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0638 - accuracy: 0.9675\n",
            "Epoch 373/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0637 - accuracy: 0.9680\n",
            "Epoch 374/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0644 - accuracy: 0.9666\n",
            "Epoch 375/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0646 - accuracy: 0.9659\n",
            "Epoch 376/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0623 - accuracy: 0.9662\n",
            "Epoch 377/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0635 - accuracy: 0.9666\n",
            "Epoch 378/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0680 - accuracy: 0.9671\n",
            "Epoch 379/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0651 - accuracy: 0.9666\n",
            "Epoch 380/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0648 - accuracy: 0.9652\n",
            "Epoch 381/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0673 - accuracy: 0.9660\n",
            "Epoch 382/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0929 - accuracy: 0.9579\n",
            "Epoch 383/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0931 - accuracy: 0.9579\n",
            "Epoch 384/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0681 - accuracy: 0.9644\n",
            "Epoch 385/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0663 - accuracy: 0.9669\n",
            "Epoch 386/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0611 - accuracy: 0.9675\n",
            "Epoch 387/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0615 - accuracy: 0.9673\n",
            "Epoch 388/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0639 - accuracy: 0.9646\n",
            "Epoch 389/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0626 - accuracy: 0.9669\n",
            "Epoch 390/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0644 - accuracy: 0.9662\n",
            "Epoch 391/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0652 - accuracy: 0.9662\n",
            "Epoch 392/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0645 - accuracy: 0.9660\n",
            "Epoch 393/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0608 - accuracy: 0.9678\n",
            "Epoch 394/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0619 - accuracy: 0.9652\n",
            "Epoch 395/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0640 - accuracy: 0.9666\n",
            "Epoch 396/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0678 - accuracy: 0.9659\n",
            "Epoch 397/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0633 - accuracy: 0.9676\n",
            "Epoch 398/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0654 - accuracy: 0.9671\n",
            "Epoch 399/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0800 - accuracy: 0.9636\n",
            "Epoch 400/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0775 - accuracy: 0.9627\n",
            "Epoch 401/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0661 - accuracy: 0.9671\n",
            "Epoch 402/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0613 - accuracy: 0.9682\n",
            "Epoch 403/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0625 - accuracy: 0.9673\n",
            "Epoch 404/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0613 - accuracy: 0.9669\n",
            "Epoch 405/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0664 - accuracy: 0.9646\n",
            "Epoch 406/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0646 - accuracy: 0.9669\n",
            "Epoch 407/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0677 - accuracy: 0.9648\n",
            "Epoch 408/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0850 - accuracy: 0.9612\n",
            "Epoch 409/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0929 - accuracy: 0.9579\n",
            "Epoch 410/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0685 - accuracy: 0.9641\n",
            "Epoch 411/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0674 - accuracy: 0.9660\n",
            "Epoch 412/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0664 - accuracy: 0.9666\n",
            "Epoch 413/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0642 - accuracy: 0.9673\n",
            "Epoch 414/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0567 - accuracy: 0.9701\n",
            "Epoch 415/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0578 - accuracy: 0.9680\n",
            "Epoch 416/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0595 - accuracy: 0.9684\n",
            "Epoch 417/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0612 - accuracy: 0.9684\n",
            "Epoch 418/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0667 - accuracy: 0.9664\n",
            "Epoch 419/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0669 - accuracy: 0.9648\n",
            "Epoch 420/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0796 - accuracy: 0.9612\n",
            "Epoch 421/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0671 - accuracy: 0.9637\n",
            "Epoch 422/500\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0668 - accuracy: 0.9676\n",
            "Epoch 423/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0623 - accuracy: 0.9671\n",
            "Epoch 424/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0577 - accuracy: 0.9705\n",
            "Epoch 425/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0570 - accuracy: 0.9712\n",
            "Epoch 426/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0597 - accuracy: 0.9701\n",
            "Epoch 427/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0634 - accuracy: 0.9682\n",
            "Epoch 428/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0662 - accuracy: 0.9664\n",
            "Epoch 429/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0710 - accuracy: 0.9643\n",
            "Epoch 430/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0677 - accuracy: 0.9641\n",
            "Epoch 431/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0615 - accuracy: 0.9696\n",
            "Epoch 432/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0693 - accuracy: 0.9664\n",
            "Epoch 433/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0872 - accuracy: 0.9612\n",
            "Epoch 434/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0754 - accuracy: 0.9644\n",
            "Epoch 435/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0602 - accuracy: 0.9691\n",
            "Epoch 436/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0602 - accuracy: 0.9696\n",
            "Epoch 437/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0581 - accuracy: 0.9692\n",
            "Epoch 438/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0609 - accuracy: 0.9689\n",
            "Epoch 439/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0617 - accuracy: 0.9662\n",
            "Epoch 440/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0650 - accuracy: 0.9680\n",
            "Epoch 441/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0638 - accuracy: 0.9673\n",
            "Epoch 442/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0605 - accuracy: 0.9673\n",
            "Epoch 443/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0663 - accuracy: 0.9653\n",
            "Epoch 444/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0607 - accuracy: 0.9689\n",
            "Epoch 445/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0596 - accuracy: 0.9689\n",
            "Epoch 446/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0594 - accuracy: 0.9685\n",
            "Epoch 447/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0652 - accuracy: 0.9664\n",
            "Epoch 448/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0678 - accuracy: 0.9660\n",
            "Epoch 449/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0702 - accuracy: 0.9676\n",
            "Epoch 450/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0593 - accuracy: 0.9680\n",
            "Epoch 451/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0593 - accuracy: 0.9684\n",
            "Epoch 452/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0669 - accuracy: 0.9666\n",
            "Epoch 453/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0676 - accuracy: 0.9666\n",
            "Epoch 454/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0726 - accuracy: 0.9653\n",
            "Epoch 455/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0633 - accuracy: 0.9664\n",
            "Epoch 456/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0625 - accuracy: 0.9684\n",
            "Epoch 457/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0587 - accuracy: 0.9701\n",
            "Epoch 458/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0586 - accuracy: 0.9682\n",
            "Epoch 459/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0602 - accuracy: 0.9682\n",
            "Epoch 460/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0711 - accuracy: 0.9643\n",
            "Epoch 461/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0765 - accuracy: 0.9653\n",
            "Epoch 462/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0816 - accuracy: 0.9611\n",
            "Epoch 463/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0707 - accuracy: 0.9666\n",
            "Epoch 464/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0578 - accuracy: 0.9691\n",
            "Epoch 465/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0557 - accuracy: 0.9707\n",
            "Epoch 466/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0584 - accuracy: 0.9700\n",
            "Epoch 467/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0577 - accuracy: 0.9703\n",
            "Epoch 468/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0576 - accuracy: 0.9689\n",
            "Epoch 469/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0611 - accuracy: 0.9671\n",
            "Epoch 470/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0587 - accuracy: 0.9669\n",
            "Epoch 471/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0654 - accuracy: 0.9666\n",
            "Epoch 472/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0600 - accuracy: 0.9694\n",
            "Epoch 473/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0568 - accuracy: 0.9703\n",
            "Epoch 474/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0601 - accuracy: 0.9696\n",
            "Epoch 475/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0661 - accuracy: 0.9678\n",
            "Epoch 476/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0695 - accuracy: 0.9659\n",
            "Epoch 477/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0727 - accuracy: 0.9648\n",
            "Epoch 478/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0673 - accuracy: 0.9687\n",
            "Epoch 479/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0573 - accuracy: 0.9703\n",
            "Epoch 480/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0610 - accuracy: 0.9659\n",
            "Epoch 481/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0612 - accuracy: 0.9675\n",
            "Epoch 482/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0595 - accuracy: 0.9696\n",
            "Epoch 483/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0595 - accuracy: 0.9660\n",
            "Epoch 484/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0593 - accuracy: 0.9689\n",
            "Epoch 485/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0606 - accuracy: 0.9691\n",
            "Epoch 486/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0649 - accuracy: 0.9673\n",
            "Epoch 487/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0654 - accuracy: 0.9687\n",
            "Epoch 488/500\n",
            "176/176 [==============================] - 1s 8ms/step - loss: 0.0588 - accuracy: 0.9689\n",
            "Epoch 489/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0586 - accuracy: 0.9700\n",
            "Epoch 490/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0570 - accuracy: 0.9710\n",
            "Epoch 491/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0589 - accuracy: 0.9694\n",
            "Epoch 492/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0600 - accuracy: 0.9692\n",
            "Epoch 493/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0685 - accuracy: 0.9673\n",
            "Epoch 494/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0782 - accuracy: 0.9628\n",
            "Epoch 495/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0683 - accuracy: 0.9671\n",
            "Epoch 496/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0642 - accuracy: 0.9691\n",
            "Epoch 497/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0610 - accuracy: 0.9687\n",
            "Epoch 498/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0603 - accuracy: 0.9707\n",
            "Epoch 499/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.0579 - accuracy: 0.9694\n",
            "Epoch 500/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.0560 - accuracy: 0.9707\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x282aac9d0>"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = keras.Sequential([\n",
        "                          keras.layers.Dense(52, input_shape = (26,), activation = 'relu'),\n",
        "                          keras.layers.Dense(208, activation = 'relu'),\n",
        "                          keras.layers.Dense(500, activation = 'relu'),\n",
        "                          keras.layers.Dense(10, activation = 'relu'),\n",
        "                          keras.layers.Dense(1, activation = 'sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'binary_crossentropy',\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "model.fit(x_train,y_train, epochs = 500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0YOY-uRlvD3",
        "outputId": "a1c3c3d6-0c48-48c9-95f5-ab6a0453b483"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "27/44 [=================>............] - ETA: 0s - loss: 3.5120 - accuracy: 0.7662"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-02-01 16:06:11.902866: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "44/44 [==============================] - 0s 4ms/step - loss: 3.3648 - accuracy: 0.7448\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[3.3648288249969482, 0.7448472380638123]"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "n1-TfJTxmKwT"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-02-01 16:06:12.306647: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        }
      ],
      "source": [
        "yp = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "h6yffOH3qOpC"
      },
      "outputs": [],
      "source": [
        "y_pred = []\n",
        "for element in yp:\n",
        "  if element > 0.5:\n",
        "    y_pred.append(1)\n",
        "  else:\n",
        "    y_pred.append(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "Ad53MFi5qbsc"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQaNlxwpqpbG",
        "outputId": "0fb5a446-b89d-4477-ffab-a4a2a7b88813"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.83      0.83      1038\n",
            "           1       0.51      0.50      0.51       369\n",
            "\n",
            "    accuracy                           0.74      1407\n",
            "   macro avg       0.67      0.67      0.67      1407\n",
            "weighted avg       0.74      0.74      0.74      1407\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "XTxKYk4Eqv-E",
        "outputId": "858b6e3e-f0fa-4754-e34c-1cb15bff4b2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(69.0, 0.5, 'Truth')"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import seaborn as sn\n",
        "cm = tf.math.confusion_matrix(labels=y_test,predictions=y_pred)\n",
        "\n",
        "plt.figure(figsize = (10,7))\n",
        "sn.heatmap(cm, annot=True, fmt='d')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Truth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwhMm8O1q2CM",
        "outputId": "369b6deb-6c9b-454b-e0f9-518a43dcb481"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-02-01 16:06:12.849834: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "176/176 [==============================] - 1s 5ms/step - loss: 0.5326 - accuracy: 0.7157\n",
            "Epoch 2/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.4345 - accuracy: 0.7881\n",
            "Epoch 3/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.4243 - accuracy: 0.7941\n",
            "Epoch 4/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.4208 - accuracy: 0.7964\n",
            "Epoch 5/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.4175 - accuracy: 0.8004\n",
            "Epoch 6/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.4151 - accuracy: 0.8014\n",
            "Epoch 7/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.4134 - accuracy: 0.8043\n",
            "Epoch 8/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.4121 - accuracy: 0.8073\n",
            "Epoch 9/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.4115 - accuracy: 0.8018\n",
            "Epoch 10/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.4095 - accuracy: 0.8057\n",
            "Epoch 11/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.4081 - accuracy: 0.8048\n",
            "Epoch 12/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.4071 - accuracy: 0.8064\n",
            "Epoch 13/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.4065 - accuracy: 0.8057\n",
            "Epoch 14/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.4069 - accuracy: 0.8032\n",
            "Epoch 15/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.4047 - accuracy: 0.8059\n",
            "Epoch 16/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.4028 - accuracy: 0.8059\n",
            "Epoch 17/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.4033 - accuracy: 0.8078\n",
            "Epoch 18/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.4018 - accuracy: 0.8085\n",
            "Epoch 19/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.4021 - accuracy: 0.8080\n",
            "Epoch 20/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.4012 - accuracy: 0.8114\n",
            "Epoch 21/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3994 - accuracy: 0.8098\n",
            "Epoch 22/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3989 - accuracy: 0.8110\n",
            "Epoch 23/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3985 - accuracy: 0.8100\n",
            "Epoch 24/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3973 - accuracy: 0.8094\n",
            "Epoch 25/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3963 - accuracy: 0.8101\n",
            "Epoch 26/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3961 - accuracy: 0.8119\n",
            "Epoch 27/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3947 - accuracy: 0.8126\n",
            "Epoch 28/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3949 - accuracy: 0.8137\n",
            "Epoch 29/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3936 - accuracy: 0.8164\n",
            "Epoch 30/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3932 - accuracy: 0.8139\n",
            "Epoch 31/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3928 - accuracy: 0.8142\n",
            "Epoch 32/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3914 - accuracy: 0.8158\n",
            "Epoch 33/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3912 - accuracy: 0.8165\n",
            "Epoch 34/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3902 - accuracy: 0.8188\n",
            "Epoch 35/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3887 - accuracy: 0.8178\n",
            "Epoch 36/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3900 - accuracy: 0.8174\n",
            "Epoch 37/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3885 - accuracy: 0.8165\n",
            "Epoch 38/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3873 - accuracy: 0.8181\n",
            "Epoch 39/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3876 - accuracy: 0.8121\n",
            "Epoch 40/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3876 - accuracy: 0.8208\n",
            "Epoch 41/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3855 - accuracy: 0.8199\n",
            "Epoch 42/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3848 - accuracy: 0.8181\n",
            "Epoch 43/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3854 - accuracy: 0.8172\n",
            "Epoch 44/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3842 - accuracy: 0.8208\n",
            "Epoch 45/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3827 - accuracy: 0.8213\n",
            "Epoch 46/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3840 - accuracy: 0.8212\n",
            "Epoch 47/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3825 - accuracy: 0.8206\n",
            "Epoch 48/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3823 - accuracy: 0.8212\n",
            "Epoch 49/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3818 - accuracy: 0.8190\n",
            "Epoch 50/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3820 - accuracy: 0.8208\n",
            "Epoch 51/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3817 - accuracy: 0.8181\n",
            "Epoch 52/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3806 - accuracy: 0.8212\n",
            "Epoch 53/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3790 - accuracy: 0.8251\n",
            "Epoch 54/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3801 - accuracy: 0.8228\n",
            "Epoch 55/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3794 - accuracy: 0.8204\n",
            "Epoch 56/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3781 - accuracy: 0.8226\n",
            "Epoch 57/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3775 - accuracy: 0.8222\n",
            "Epoch 58/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3779 - accuracy: 0.8235\n",
            "Epoch 59/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3774 - accuracy: 0.8231\n",
            "Epoch 60/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3757 - accuracy: 0.8251\n",
            "Epoch 61/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3756 - accuracy: 0.8267\n",
            "Epoch 62/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3771 - accuracy: 0.8212\n",
            "Epoch 63/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3750 - accuracy: 0.8251\n",
            "Epoch 64/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3742 - accuracy: 0.8242\n",
            "Epoch 65/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3735 - accuracy: 0.8260\n",
            "Epoch 66/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3745 - accuracy: 0.8277\n",
            "Epoch 67/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3748 - accuracy: 0.8251\n",
            "Epoch 68/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3728 - accuracy: 0.8277\n",
            "Epoch 69/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3732 - accuracy: 0.8222\n",
            "Epoch 70/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3727 - accuracy: 0.8261\n",
            "Epoch 71/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3733 - accuracy: 0.8251\n",
            "Epoch 72/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3715 - accuracy: 0.8236\n",
            "Epoch 73/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3718 - accuracy: 0.8279\n",
            "Epoch 74/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3715 - accuracy: 0.8244\n",
            "Epoch 75/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3700 - accuracy: 0.8244\n",
            "Epoch 76/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3710 - accuracy: 0.8267\n",
            "Epoch 77/500\n",
            "176/176 [==============================] - 1s 7ms/step - loss: 0.3697 - accuracy: 0.8290\n",
            "Epoch 78/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3701 - accuracy: 0.8279\n",
            "Epoch 79/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3678 - accuracy: 0.8279\n",
            "Epoch 80/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3698 - accuracy: 0.8242\n",
            "Epoch 81/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3685 - accuracy: 0.8263\n",
            "Epoch 82/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3678 - accuracy: 0.8276\n",
            "Epoch 83/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3678 - accuracy: 0.8295\n",
            "Epoch 84/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3670 - accuracy: 0.8286\n",
            "Epoch 85/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3667 - accuracy: 0.8274\n",
            "Epoch 86/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3670 - accuracy: 0.8254\n",
            "Epoch 87/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3668 - accuracy: 0.8283\n",
            "Epoch 88/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3654 - accuracy: 0.8270\n",
            "Epoch 89/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3653 - accuracy: 0.8304\n",
            "Epoch 90/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3659 - accuracy: 0.8279\n",
            "Epoch 91/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3634 - accuracy: 0.8316\n",
            "Epoch 92/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3651 - accuracy: 0.8318\n",
            "Epoch 93/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3645 - accuracy: 0.8286\n",
            "Epoch 94/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3649 - accuracy: 0.8295\n",
            "Epoch 95/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3642 - accuracy: 0.8292\n",
            "Epoch 96/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3628 - accuracy: 0.8295\n",
            "Epoch 97/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3625 - accuracy: 0.8311\n",
            "Epoch 98/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3627 - accuracy: 0.8302\n",
            "Epoch 99/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3630 - accuracy: 0.8331\n",
            "Epoch 100/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3628 - accuracy: 0.8284\n",
            "Epoch 101/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3633 - accuracy: 0.8315\n",
            "Epoch 102/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3613 - accuracy: 0.8318\n",
            "Epoch 103/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3629 - accuracy: 0.8295\n",
            "Epoch 104/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3606 - accuracy: 0.8290\n",
            "Epoch 105/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3629 - accuracy: 0.8304\n",
            "Epoch 106/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3606 - accuracy: 0.8350\n",
            "Epoch 107/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3604 - accuracy: 0.8347\n",
            "Epoch 108/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3593 - accuracy: 0.8329\n",
            "Epoch 109/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3617 - accuracy: 0.8297\n",
            "Epoch 110/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3595 - accuracy: 0.8332\n",
            "Epoch 111/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3610 - accuracy: 0.8324\n",
            "Epoch 112/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3596 - accuracy: 0.8332\n",
            "Epoch 113/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3593 - accuracy: 0.8315\n",
            "Epoch 114/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3602 - accuracy: 0.8340\n",
            "Epoch 115/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3584 - accuracy: 0.8336\n",
            "Epoch 116/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3588 - accuracy: 0.8327\n",
            "Epoch 117/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3590 - accuracy: 0.8309\n",
            "Epoch 118/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3586 - accuracy: 0.8341\n",
            "Epoch 119/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3585 - accuracy: 0.8329\n",
            "Epoch 120/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3584 - accuracy: 0.8327\n",
            "Epoch 121/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3574 - accuracy: 0.8324\n",
            "Epoch 122/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3574 - accuracy: 0.8348\n",
            "Epoch 123/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3564 - accuracy: 0.8357\n",
            "Epoch 124/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3575 - accuracy: 0.8386\n",
            "Epoch 125/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3568 - accuracy: 0.8347\n",
            "Epoch 126/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3564 - accuracy: 0.8327\n",
            "Epoch 127/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3559 - accuracy: 0.8336\n",
            "Epoch 128/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3545 - accuracy: 0.8347\n",
            "Epoch 129/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3551 - accuracy: 0.8350\n",
            "Epoch 130/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3553 - accuracy: 0.8364\n",
            "Epoch 131/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3554 - accuracy: 0.8311\n",
            "Epoch 132/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3551 - accuracy: 0.8343\n",
            "Epoch 133/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3545 - accuracy: 0.8329\n",
            "Epoch 134/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3551 - accuracy: 0.8348\n",
            "Epoch 135/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3539 - accuracy: 0.8357\n",
            "Epoch 136/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3525 - accuracy: 0.8363\n",
            "Epoch 137/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3539 - accuracy: 0.8327\n",
            "Epoch 138/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3543 - accuracy: 0.8363\n",
            "Epoch 139/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3536 - accuracy: 0.8368\n",
            "Epoch 140/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3524 - accuracy: 0.8336\n",
            "Epoch 141/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3518 - accuracy: 0.8366\n",
            "Epoch 142/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3521 - accuracy: 0.8379\n",
            "Epoch 143/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3526 - accuracy: 0.8348\n",
            "Epoch 144/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3522 - accuracy: 0.8336\n",
            "Epoch 145/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3520 - accuracy: 0.8354\n",
            "Epoch 146/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3530 - accuracy: 0.8377\n",
            "Epoch 147/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3499 - accuracy: 0.8350\n",
            "Epoch 148/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3511 - accuracy: 0.8380\n",
            "Epoch 149/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3498 - accuracy: 0.8348\n",
            "Epoch 150/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3499 - accuracy: 0.8391\n",
            "Epoch 151/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3511 - accuracy: 0.8375\n",
            "Epoch 152/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3495 - accuracy: 0.8366\n",
            "Epoch 153/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3509 - accuracy: 0.8377\n",
            "Epoch 154/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3500 - accuracy: 0.8404\n",
            "Epoch 155/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3496 - accuracy: 0.8384\n",
            "Epoch 156/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3494 - accuracy: 0.8388\n",
            "Epoch 157/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3502 - accuracy: 0.8373\n",
            "Epoch 158/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3491 - accuracy: 0.8368\n",
            "Epoch 159/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3478 - accuracy: 0.8382\n",
            "Epoch 160/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3493 - accuracy: 0.8368\n",
            "Epoch 161/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3497 - accuracy: 0.8384\n",
            "Epoch 162/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3479 - accuracy: 0.8379\n",
            "Epoch 163/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3488 - accuracy: 0.8372\n",
            "Epoch 164/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3478 - accuracy: 0.8418\n",
            "Epoch 165/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3468 - accuracy: 0.8404\n",
            "Epoch 166/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3471 - accuracy: 0.8434\n",
            "Epoch 167/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3473 - accuracy: 0.8411\n",
            "Epoch 168/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3461 - accuracy: 0.8412\n",
            "Epoch 169/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3456 - accuracy: 0.8396\n",
            "Epoch 170/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3449 - accuracy: 0.8423\n",
            "Epoch 171/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3455 - accuracy: 0.8398\n",
            "Epoch 172/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3465 - accuracy: 0.8375\n",
            "Epoch 173/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3459 - accuracy: 0.8404\n",
            "Epoch 174/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3471 - accuracy: 0.8396\n",
            "Epoch 175/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3445 - accuracy: 0.8421\n",
            "Epoch 176/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3448 - accuracy: 0.8391\n",
            "Epoch 177/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3438 - accuracy: 0.8400\n",
            "Epoch 178/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3443 - accuracy: 0.8372\n",
            "Epoch 179/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3451 - accuracy: 0.8434\n",
            "Epoch 180/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3447 - accuracy: 0.8414\n",
            "Epoch 181/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3442 - accuracy: 0.8427\n",
            "Epoch 182/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3447 - accuracy: 0.8405\n",
            "Epoch 183/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3452 - accuracy: 0.8366\n",
            "Epoch 184/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3431 - accuracy: 0.8428\n",
            "Epoch 185/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3434 - accuracy: 0.8375\n",
            "Epoch 186/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3418 - accuracy: 0.8418\n",
            "Epoch 187/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3414 - accuracy: 0.8425\n",
            "Epoch 188/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3418 - accuracy: 0.8416\n",
            "Epoch 189/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3428 - accuracy: 0.8402\n",
            "Epoch 190/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3420 - accuracy: 0.8420\n",
            "Epoch 191/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3423 - accuracy: 0.8428\n",
            "Epoch 192/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3435 - accuracy: 0.8377\n",
            "Epoch 193/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3435 - accuracy: 0.8405\n",
            "Epoch 194/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3408 - accuracy: 0.8414\n",
            "Epoch 195/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3423 - accuracy: 0.8425\n",
            "Epoch 196/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3407 - accuracy: 0.8468\n",
            "Epoch 197/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3409 - accuracy: 0.8407\n",
            "Epoch 198/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3407 - accuracy: 0.8420\n",
            "Epoch 199/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3403 - accuracy: 0.8434\n",
            "Epoch 200/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3393 - accuracy: 0.8432\n",
            "Epoch 201/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3405 - accuracy: 0.8439\n",
            "Epoch 202/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3390 - accuracy: 0.8416\n",
            "Epoch 203/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3405 - accuracy: 0.8446\n",
            "Epoch 204/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3380 - accuracy: 0.8420\n",
            "Epoch 205/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3404 - accuracy: 0.8453\n",
            "Epoch 206/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3393 - accuracy: 0.8430\n",
            "Epoch 207/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3399 - accuracy: 0.8460\n",
            "Epoch 208/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3371 - accuracy: 0.8453\n",
            "Epoch 209/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3370 - accuracy: 0.8420\n",
            "Epoch 210/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3384 - accuracy: 0.8457\n",
            "Epoch 211/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3378 - accuracy: 0.8428\n",
            "Epoch 212/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3376 - accuracy: 0.8450\n",
            "Epoch 213/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3366 - accuracy: 0.8478\n",
            "Epoch 214/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3372 - accuracy: 0.8464\n",
            "Epoch 215/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3391 - accuracy: 0.8436\n",
            "Epoch 216/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3376 - accuracy: 0.8407\n",
            "Epoch 217/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3371 - accuracy: 0.8453\n",
            "Epoch 218/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3367 - accuracy: 0.8466\n",
            "Epoch 219/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3378 - accuracy: 0.8466\n",
            "Epoch 220/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3366 - accuracy: 0.8453\n",
            "Epoch 221/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3357 - accuracy: 0.8444\n",
            "Epoch 222/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3366 - accuracy: 0.8441\n",
            "Epoch 223/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3350 - accuracy: 0.8460\n",
            "Epoch 224/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3351 - accuracy: 0.8484\n",
            "Epoch 225/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3357 - accuracy: 0.8453\n",
            "Epoch 226/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3355 - accuracy: 0.8455\n",
            "Epoch 227/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3347 - accuracy: 0.8464\n",
            "Epoch 228/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3343 - accuracy: 0.8482\n",
            "Epoch 229/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3349 - accuracy: 0.8450\n",
            "Epoch 230/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3350 - accuracy: 0.8430\n",
            "Epoch 231/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3342 - accuracy: 0.8453\n",
            "Epoch 232/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3333 - accuracy: 0.8501\n",
            "Epoch 233/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3353 - accuracy: 0.8469\n",
            "Epoch 234/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3341 - accuracy: 0.8423\n",
            "Epoch 235/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3346 - accuracy: 0.8457\n",
            "Epoch 236/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3350 - accuracy: 0.8459\n",
            "Epoch 237/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3329 - accuracy: 0.8508\n",
            "Epoch 238/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3332 - accuracy: 0.8460\n",
            "Epoch 239/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3343 - accuracy: 0.8464\n",
            "Epoch 240/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3348 - accuracy: 0.8452\n",
            "Epoch 241/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3352 - accuracy: 0.8459\n",
            "Epoch 242/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3332 - accuracy: 0.8453\n",
            "Epoch 243/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3330 - accuracy: 0.8487\n",
            "Epoch 244/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3321 - accuracy: 0.8478\n",
            "Epoch 245/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3339 - accuracy: 0.8464\n",
            "Epoch 246/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3317 - accuracy: 0.8494\n",
            "Epoch 247/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3324 - accuracy: 0.8489\n",
            "Epoch 248/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3314 - accuracy: 0.8492\n",
            "Epoch 249/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3312 - accuracy: 0.8498\n",
            "Epoch 250/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3329 - accuracy: 0.8498\n",
            "Epoch 251/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3334 - accuracy: 0.8464\n",
            "Epoch 252/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3315 - accuracy: 0.8468\n",
            "Epoch 253/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3327 - accuracy: 0.8484\n",
            "Epoch 254/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3302 - accuracy: 0.8492\n",
            "Epoch 255/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3308 - accuracy: 0.8462\n",
            "Epoch 256/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3329 - accuracy: 0.8485\n",
            "Epoch 257/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3337 - accuracy: 0.8460\n",
            "Epoch 258/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3303 - accuracy: 0.8519\n",
            "Epoch 259/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3304 - accuracy: 0.8476\n",
            "Epoch 260/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3301 - accuracy: 0.8480\n",
            "Epoch 261/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3319 - accuracy: 0.8501\n",
            "Epoch 262/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3304 - accuracy: 0.8508\n",
            "Epoch 263/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3308 - accuracy: 0.8487\n",
            "Epoch 264/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3296 - accuracy: 0.8500\n",
            "Epoch 265/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3295 - accuracy: 0.8475\n",
            "Epoch 266/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3293 - accuracy: 0.8500\n",
            "Epoch 267/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3318 - accuracy: 0.8484\n",
            "Epoch 268/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3294 - accuracy: 0.8491\n",
            "Epoch 269/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3302 - accuracy: 0.8478\n",
            "Epoch 270/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3301 - accuracy: 0.8491\n",
            "Epoch 271/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3302 - accuracy: 0.8487\n",
            "Epoch 272/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3289 - accuracy: 0.8500\n",
            "Epoch 273/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3286 - accuracy: 0.8516\n",
            "Epoch 274/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3284 - accuracy: 0.8455\n",
            "Epoch 275/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3319 - accuracy: 0.8478\n",
            "Epoch 276/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3283 - accuracy: 0.8498\n",
            "Epoch 277/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3288 - accuracy: 0.8494\n",
            "Epoch 278/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3277 - accuracy: 0.8519\n",
            "Epoch 279/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3289 - accuracy: 0.8501\n",
            "Epoch 280/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3275 - accuracy: 0.8516\n",
            "Epoch 281/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3266 - accuracy: 0.8501\n",
            "Epoch 282/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3286 - accuracy: 0.8500\n",
            "Epoch 283/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3277 - accuracy: 0.8505\n",
            "Epoch 284/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3297 - accuracy: 0.8468\n",
            "Epoch 285/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3293 - accuracy: 0.8475\n",
            "Epoch 286/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3282 - accuracy: 0.8487\n",
            "Epoch 287/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3296 - accuracy: 0.8464\n",
            "Epoch 288/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3273 - accuracy: 0.8475\n",
            "Epoch 289/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3296 - accuracy: 0.8480\n",
            "Epoch 290/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3281 - accuracy: 0.8489\n",
            "Epoch 291/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3272 - accuracy: 0.8491\n",
            "Epoch 292/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3278 - accuracy: 0.8501\n",
            "Epoch 293/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3278 - accuracy: 0.8514\n",
            "Epoch 294/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3277 - accuracy: 0.8503\n",
            "Epoch 295/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3265 - accuracy: 0.8512\n",
            "Epoch 296/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3259 - accuracy: 0.8464\n",
            "Epoch 297/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3261 - accuracy: 0.8503\n",
            "Epoch 298/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3286 - accuracy: 0.8500\n",
            "Epoch 299/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3260 - accuracy: 0.8517\n",
            "Epoch 300/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3260 - accuracy: 0.8476\n",
            "Epoch 301/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3268 - accuracy: 0.8501\n",
            "Epoch 302/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3269 - accuracy: 0.8498\n",
            "Epoch 303/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3264 - accuracy: 0.8507\n",
            "Epoch 304/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3268 - accuracy: 0.8505\n",
            "Epoch 305/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3246 - accuracy: 0.8507\n",
            "Epoch 306/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3253 - accuracy: 0.8469\n",
            "Epoch 307/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3291 - accuracy: 0.8484\n",
            "Epoch 308/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3260 - accuracy: 0.8491\n",
            "Epoch 309/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3249 - accuracy: 0.8521\n",
            "Epoch 310/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3241 - accuracy: 0.8516\n",
            "Epoch 311/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3252 - accuracy: 0.8498\n",
            "Epoch 312/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3230 - accuracy: 0.8530\n",
            "Epoch 313/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3239 - accuracy: 0.8524\n",
            "Epoch 314/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3245 - accuracy: 0.8496\n",
            "Epoch 315/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3248 - accuracy: 0.8523\n",
            "Epoch 316/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3241 - accuracy: 0.8510\n",
            "Epoch 317/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3244 - accuracy: 0.8503\n",
            "Epoch 318/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3235 - accuracy: 0.8526\n",
            "Epoch 319/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3236 - accuracy: 0.8510\n",
            "Epoch 320/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3218 - accuracy: 0.8521\n",
            "Epoch 321/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3213 - accuracy: 0.8558\n",
            "Epoch 322/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3234 - accuracy: 0.8516\n",
            "Epoch 323/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3218 - accuracy: 0.8501\n",
            "Epoch 324/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3219 - accuracy: 0.8524\n",
            "Epoch 325/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3211 - accuracy: 0.8546\n",
            "Epoch 326/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3224 - accuracy: 0.8476\n",
            "Epoch 327/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3211 - accuracy: 0.8517\n",
            "Epoch 328/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3233 - accuracy: 0.8507\n",
            "Epoch 329/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3246 - accuracy: 0.8482\n",
            "Epoch 330/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3211 - accuracy: 0.8521\n",
            "Epoch 331/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3206 - accuracy: 0.8537\n",
            "Epoch 332/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3213 - accuracy: 0.8526\n",
            "Epoch 333/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3221 - accuracy: 0.8533\n",
            "Epoch 334/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3208 - accuracy: 0.8510\n",
            "Epoch 335/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3203 - accuracy: 0.8542\n",
            "Epoch 336/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3196 - accuracy: 0.8551\n",
            "Epoch 337/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3196 - accuracy: 0.8542\n",
            "Epoch 338/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3202 - accuracy: 0.8496\n",
            "Epoch 339/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3208 - accuracy: 0.8517\n",
            "Epoch 340/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3176 - accuracy: 0.8551\n",
            "Epoch 341/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3198 - accuracy: 0.8560\n",
            "Epoch 342/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3191 - accuracy: 0.8548\n",
            "Epoch 343/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3191 - accuracy: 0.8528\n",
            "Epoch 344/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3206 - accuracy: 0.8542\n",
            "Epoch 345/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3193 - accuracy: 0.8535\n",
            "Epoch 346/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3176 - accuracy: 0.8548\n",
            "Epoch 347/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3197 - accuracy: 0.8549\n",
            "Epoch 348/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3180 - accuracy: 0.8535\n",
            "Epoch 349/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3186 - accuracy: 0.8517\n",
            "Epoch 350/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3177 - accuracy: 0.8553\n",
            "Epoch 351/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3169 - accuracy: 0.8539\n",
            "Epoch 352/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3177 - accuracy: 0.8535\n",
            "Epoch 353/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3172 - accuracy: 0.8542\n",
            "Epoch 354/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3176 - accuracy: 0.8556\n",
            "Epoch 355/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3180 - accuracy: 0.8539\n",
            "Epoch 356/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3177 - accuracy: 0.8524\n",
            "Epoch 357/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3176 - accuracy: 0.8560\n",
            "Epoch 358/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3169 - accuracy: 0.8558\n",
            "Epoch 359/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3179 - accuracy: 0.8512\n",
            "Epoch 360/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3171 - accuracy: 0.8553\n",
            "Epoch 361/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3171 - accuracy: 0.8542\n",
            "Epoch 362/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3169 - accuracy: 0.8535\n",
            "Epoch 363/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3154 - accuracy: 0.8526\n",
            "Epoch 364/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3166 - accuracy: 0.8581\n",
            "Epoch 365/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3174 - accuracy: 0.8564\n",
            "Epoch 366/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3160 - accuracy: 0.8523\n",
            "Epoch 367/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3154 - accuracy: 0.8526\n",
            "Epoch 368/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3159 - accuracy: 0.8517\n",
            "Epoch 369/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3182 - accuracy: 0.8519\n",
            "Epoch 370/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3149 - accuracy: 0.8564\n",
            "Epoch 371/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3168 - accuracy: 0.8528\n",
            "Epoch 372/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3147 - accuracy: 0.8572\n",
            "Epoch 373/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3157 - accuracy: 0.8562\n",
            "Epoch 374/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3149 - accuracy: 0.8560\n",
            "Epoch 375/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3135 - accuracy: 0.8558\n",
            "Epoch 376/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3150 - accuracy: 0.8558\n",
            "Epoch 377/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3143 - accuracy: 0.8571\n",
            "Epoch 378/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3155 - accuracy: 0.8539\n",
            "Epoch 379/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3155 - accuracy: 0.8578\n",
            "Epoch 380/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3129 - accuracy: 0.8583\n",
            "Epoch 381/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3150 - accuracy: 0.8530\n",
            "Epoch 382/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3138 - accuracy: 0.8535\n",
            "Epoch 383/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3151 - accuracy: 0.8551\n",
            "Epoch 384/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3124 - accuracy: 0.8576\n",
            "Epoch 385/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3130 - accuracy: 0.8539\n",
            "Epoch 386/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3128 - accuracy: 0.8555\n",
            "Epoch 387/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3122 - accuracy: 0.8578\n",
            "Epoch 388/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3120 - accuracy: 0.8556\n",
            "Epoch 389/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3120 - accuracy: 0.8578\n",
            "Epoch 390/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3127 - accuracy: 0.8578\n",
            "Epoch 391/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3128 - accuracy: 0.8560\n",
            "Epoch 392/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3115 - accuracy: 0.8576\n",
            "Epoch 393/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3126 - accuracy: 0.8578\n",
            "Epoch 394/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3116 - accuracy: 0.8565\n",
            "Epoch 395/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3102 - accuracy: 0.8551\n",
            "Epoch 396/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3123 - accuracy: 0.8553\n",
            "Epoch 397/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3104 - accuracy: 0.8583\n",
            "Epoch 398/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3118 - accuracy: 0.8551\n",
            "Epoch 399/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3095 - accuracy: 0.8610\n",
            "Epoch 400/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3109 - accuracy: 0.8560\n",
            "Epoch 401/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3139 - accuracy: 0.8549\n",
            "Epoch 402/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3099 - accuracy: 0.8553\n",
            "Epoch 403/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3112 - accuracy: 0.8580\n",
            "Epoch 404/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3110 - accuracy: 0.8580\n",
            "Epoch 405/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3096 - accuracy: 0.8610\n",
            "Epoch 406/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3106 - accuracy: 0.8574\n",
            "Epoch 407/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3093 - accuracy: 0.8542\n",
            "Epoch 408/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3089 - accuracy: 0.8569\n",
            "Epoch 409/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3098 - accuracy: 0.8569\n",
            "Epoch 410/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3098 - accuracy: 0.8558\n",
            "Epoch 411/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3105 - accuracy: 0.8576\n",
            "Epoch 412/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3102 - accuracy: 0.8572\n",
            "Epoch 413/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3089 - accuracy: 0.8592\n",
            "Epoch 414/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3103 - accuracy: 0.8569\n",
            "Epoch 415/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3100 - accuracy: 0.8564\n",
            "Epoch 416/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3098 - accuracy: 0.8564\n",
            "Epoch 417/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3081 - accuracy: 0.8588\n",
            "Epoch 418/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3087 - accuracy: 0.8569\n",
            "Epoch 419/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3101 - accuracy: 0.8576\n",
            "Epoch 420/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3085 - accuracy: 0.8592\n",
            "Epoch 421/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3071 - accuracy: 0.8581\n",
            "Epoch 422/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3089 - accuracy: 0.8596\n",
            "Epoch 423/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3098 - accuracy: 0.8576\n",
            "Epoch 424/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3099 - accuracy: 0.8564\n",
            "Epoch 425/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3087 - accuracy: 0.8585\n",
            "Epoch 426/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3082 - accuracy: 0.8597\n",
            "Epoch 427/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3068 - accuracy: 0.8596\n",
            "Epoch 428/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3074 - accuracy: 0.8580\n",
            "Epoch 429/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3064 - accuracy: 0.8594\n",
            "Epoch 430/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3081 - accuracy: 0.8612\n",
            "Epoch 431/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3058 - accuracy: 0.8590\n",
            "Epoch 432/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3064 - accuracy: 0.8620\n",
            "Epoch 433/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3053 - accuracy: 0.8597\n",
            "Epoch 434/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3059 - accuracy: 0.8562\n",
            "Epoch 435/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3073 - accuracy: 0.8606\n",
            "Epoch 436/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3055 - accuracy: 0.8624\n",
            "Epoch 437/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3068 - accuracy: 0.8581\n",
            "Epoch 438/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3087 - accuracy: 0.8556\n",
            "Epoch 439/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3051 - accuracy: 0.8578\n",
            "Epoch 440/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3064 - accuracy: 0.8601\n",
            "Epoch 441/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3061 - accuracy: 0.8576\n",
            "Epoch 442/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3053 - accuracy: 0.8613\n",
            "Epoch 443/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3076 - accuracy: 0.8574\n",
            "Epoch 444/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3080 - accuracy: 0.8597\n",
            "Epoch 445/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3062 - accuracy: 0.8610\n",
            "Epoch 446/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3042 - accuracy: 0.8576\n",
            "Epoch 447/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3064 - accuracy: 0.8581\n",
            "Epoch 448/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3042 - accuracy: 0.8599\n",
            "Epoch 449/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3047 - accuracy: 0.8620\n",
            "Epoch 450/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3037 - accuracy: 0.8599\n",
            "Epoch 451/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3043 - accuracy: 0.8628\n",
            "Epoch 452/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3065 - accuracy: 0.8610\n",
            "Epoch 453/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3061 - accuracy: 0.8615\n",
            "Epoch 454/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3038 - accuracy: 0.8619\n",
            "Epoch 455/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3051 - accuracy: 0.8583\n",
            "Epoch 456/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3054 - accuracy: 0.8596\n",
            "Epoch 457/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3036 - accuracy: 0.8606\n",
            "Epoch 458/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3049 - accuracy: 0.8604\n",
            "Epoch 459/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3012 - accuracy: 0.8619\n",
            "Epoch 460/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3027 - accuracy: 0.8601\n",
            "Epoch 461/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3037 - accuracy: 0.8574\n",
            "Epoch 462/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3034 - accuracy: 0.8594\n",
            "Epoch 463/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3054 - accuracy: 0.8590\n",
            "Epoch 464/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3035 - accuracy: 0.8608\n",
            "Epoch 465/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3037 - accuracy: 0.8613\n",
            "Epoch 466/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3060 - accuracy: 0.8581\n",
            "Epoch 467/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3020 - accuracy: 0.8620\n",
            "Epoch 468/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3017 - accuracy: 0.8597\n",
            "Epoch 469/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3032 - accuracy: 0.8629\n",
            "Epoch 470/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3042 - accuracy: 0.8613\n",
            "Epoch 471/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3020 - accuracy: 0.8588\n",
            "Epoch 472/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3046 - accuracy: 0.8599\n",
            "Epoch 473/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3005 - accuracy: 0.8604\n",
            "Epoch 474/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3028 - accuracy: 0.8588\n",
            "Epoch 475/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3031 - accuracy: 0.8626\n",
            "Epoch 476/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3021 - accuracy: 0.8599\n",
            "Epoch 477/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3022 - accuracy: 0.8597\n",
            "Epoch 478/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3022 - accuracy: 0.8620\n",
            "Epoch 479/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3024 - accuracy: 0.8548\n",
            "Epoch 480/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3004 - accuracy: 0.8624\n",
            "Epoch 481/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3032 - accuracy: 0.8608\n",
            "Epoch 482/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3007 - accuracy: 0.8619\n",
            "Epoch 483/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3009 - accuracy: 0.8620\n",
            "Epoch 484/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3012 - accuracy: 0.8617\n",
            "Epoch 485/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3022 - accuracy: 0.8585\n",
            "Epoch 486/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3000 - accuracy: 0.8622\n",
            "Epoch 487/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3013 - accuracy: 0.8626\n",
            "Epoch 488/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3009 - accuracy: 0.8615\n",
            "Epoch 489/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3007 - accuracy: 0.8622\n",
            "Epoch 490/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3013 - accuracy: 0.8608\n",
            "Epoch 491/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.2998 - accuracy: 0.8624\n",
            "Epoch 492/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3014 - accuracy: 0.8603\n",
            "Epoch 493/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3010 - accuracy: 0.8590\n",
            "Epoch 494/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.2988 - accuracy: 0.8604\n",
            "Epoch 495/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.2982 - accuracy: 0.8622\n",
            "Epoch 496/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3032 - accuracy: 0.8626\n",
            "Epoch 497/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3009 - accuracy: 0.8608\n",
            "Epoch 498/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.2992 - accuracy: 0.8645\n",
            "Epoch 499/500\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.2999 - accuracy: 0.8612\n",
            "Epoch 500/500\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3006 - accuracy: 0.8594\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x11a6d6a30>"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = keras.Sequential([\n",
        "                          keras.layers.Dense(26, input_shape = (26,), activation = 'relu'),\n",
        "                          keras.layers.Dense(15, activation = 'relu'),\n",
        "                          keras.layers.Dense(1, activation = 'sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'binary_crossentropy',\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "model.fit(x_train,y_train, epochs = 500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9RLF70jtUxe",
        "outputId": "71c4dfcf-f73e-4981-a48f-cfb17b7334e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "32/44 [====================>.........] - ETA: 0s - loss: 0.6120 - accuracy: 0.7646"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-02-01 16:14:00.245243: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6290 - accuracy: 0.7584\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.6289690136909485, 0.7583511471748352]"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "YhjD8TxgtZCb",
        "outputId": "8f986d00-6853-42dd-dafe-30cf75d11dd2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(69.0, 0.5, 'Truth')"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import seaborn as sn\n",
        "cm = tf.math.confusion_matrix(labels=y_test,predictions=y_pred)\n",
        "\n",
        "plt.figure(figsize = (10,7))\n",
        "sn.heatmap(cm, annot=True, fmt='d')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Truth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Solving the problem of Imbalance Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "HPkfG2p6uGSW"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "def ANN(x_train, y_train, x_test, y_test, loss, weights):\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.Dense(26, input_shape=(26,), activation = 'relu'),\n",
        "        keras.layers.Dense(15, activation = 'relu'),\n",
        "        keras.layers.Dense(1, activation = 'sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer = 'adam', loss = loss, metrics = ['accuracy'])\n",
        "\n",
        "    if weights == -1:\n",
        "        model.fit(x_train, y_train, epochs = 100)\n",
        "    else:\n",
        "        model.fit(x_train, y_train, epochs = 100, class_weight = weights)\n",
        "\n",
        "    print(model.evaluate(x_test, y_test))\n",
        "\n",
        "    y_pred = np.round(model.predict(x_test))\n",
        "\n",
        "    print(\"Classification Report: - \\n\", classification_report(y_test, y_pred))\n",
        "    return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "  9/176 [>.............................] - ETA: 1s - loss: 0.7498 - accuracy: 0.2778 "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-02-01 16:29:25.696950: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "176/176 [==============================] - 1s 5ms/step - loss: 0.5340 - accuracy: 0.7077\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.4346 - accuracy: 0.7863\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.4244 - accuracy: 0.7959\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.4208 - accuracy: 0.7982\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.4176 - accuracy: 0.7984\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.4161 - accuracy: 0.8032\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.4132 - accuracy: 0.8057\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.4125 - accuracy: 0.8030\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.4115 - accuracy: 0.8030\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.4102 - accuracy: 0.8041\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.4084 - accuracy: 0.8069\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.4076 - accuracy: 0.8082\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.4062 - accuracy: 0.8044\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.4051 - accuracy: 0.8080\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.4041 - accuracy: 0.8094\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.4030 - accuracy: 0.8110\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.4042 - accuracy: 0.8080\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.4020 - accuracy: 0.8098\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.4012 - accuracy: 0.8116\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.4002 - accuracy: 0.8082\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3997 - accuracy: 0.8112\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3992 - accuracy: 0.8119\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3984 - accuracy: 0.8119\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3979 - accuracy: 0.8128\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3978 - accuracy: 0.8101\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3965 - accuracy: 0.8098\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3960 - accuracy: 0.8146\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3942 - accuracy: 0.8137\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3937 - accuracy: 0.8142\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3935 - accuracy: 0.8128\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3929 - accuracy: 0.8126\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3916 - accuracy: 0.8140\n",
            "Epoch 33/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3914 - accuracy: 0.8144\n",
            "Epoch 34/100\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3894 - accuracy: 0.8165\n",
            "Epoch 35/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3895 - accuracy: 0.8151\n",
            "Epoch 36/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3890 - accuracy: 0.8156\n",
            "Epoch 37/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3878 - accuracy: 0.8151\n",
            "Epoch 38/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3866 - accuracy: 0.8156\n",
            "Epoch 39/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3871 - accuracy: 0.8167\n",
            "Epoch 40/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3861 - accuracy: 0.8162\n",
            "Epoch 41/100\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3859 - accuracy: 0.8169\n",
            "Epoch 42/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3852 - accuracy: 0.8162\n",
            "Epoch 43/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3852 - accuracy: 0.8149\n",
            "Epoch 44/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3835 - accuracy: 0.8178\n",
            "Epoch 45/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3840 - accuracy: 0.8185\n",
            "Epoch 46/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3825 - accuracy: 0.8197\n",
            "Epoch 47/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3821 - accuracy: 0.8196\n",
            "Epoch 48/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3809 - accuracy: 0.8210\n",
            "Epoch 49/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3803 - accuracy: 0.8190\n",
            "Epoch 50/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3795 - accuracy: 0.8213\n",
            "Epoch 51/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3799 - accuracy: 0.8180\n",
            "Epoch 52/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3786 - accuracy: 0.8190\n",
            "Epoch 53/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3786 - accuracy: 0.8220\n",
            "Epoch 54/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3776 - accuracy: 0.8210\n",
            "Epoch 55/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3771 - accuracy: 0.8203\n",
            "Epoch 56/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3770 - accuracy: 0.8197\n",
            "Epoch 57/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3758 - accuracy: 0.8210\n",
            "Epoch 58/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3768 - accuracy: 0.8222\n",
            "Epoch 59/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3745 - accuracy: 0.8261\n",
            "Epoch 60/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3754 - accuracy: 0.8199\n",
            "Epoch 61/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3758 - accuracy: 0.8220\n",
            "Epoch 62/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3754 - accuracy: 0.8210\n",
            "Epoch 63/100\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 0.3747 - accuracy: 0.8210\n",
            "Epoch 64/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3730 - accuracy: 0.8228\n",
            "Epoch 65/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3738 - accuracy: 0.8231\n",
            "Epoch 66/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3722 - accuracy: 0.8242\n",
            "Epoch 67/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3737 - accuracy: 0.8251\n",
            "Epoch 68/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3726 - accuracy: 0.8226\n",
            "Epoch 69/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3716 - accuracy: 0.8217\n",
            "Epoch 70/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3720 - accuracy: 0.8270\n",
            "Epoch 71/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3707 - accuracy: 0.8226\n",
            "Epoch 72/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3720 - accuracy: 0.8272\n",
            "Epoch 73/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3696 - accuracy: 0.8254\n",
            "Epoch 74/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3702 - accuracy: 0.8219\n",
            "Epoch 75/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3691 - accuracy: 0.8245\n",
            "Epoch 76/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3701 - accuracy: 0.8215\n",
            "Epoch 77/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3682 - accuracy: 0.8256\n",
            "Epoch 78/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3691 - accuracy: 0.8256\n",
            "Epoch 79/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3682 - accuracy: 0.8252\n",
            "Epoch 80/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3684 - accuracy: 0.8260\n",
            "Epoch 81/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3691 - accuracy: 0.8240\n",
            "Epoch 82/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3682 - accuracy: 0.8260\n",
            "Epoch 83/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3690 - accuracy: 0.8245\n",
            "Epoch 84/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3662 - accuracy: 0.8276\n",
            "Epoch 85/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3655 - accuracy: 0.8288\n",
            "Epoch 86/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3650 - accuracy: 0.8295\n",
            "Epoch 87/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3655 - accuracy: 0.8270\n",
            "Epoch 88/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3647 - accuracy: 0.8274\n",
            "Epoch 89/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3664 - accuracy: 0.8256\n",
            "Epoch 90/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3642 - accuracy: 0.8288\n",
            "Epoch 91/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3658 - accuracy: 0.8226\n",
            "Epoch 92/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3648 - accuracy: 0.8293\n",
            "Epoch 93/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3642 - accuracy: 0.8281\n",
            "Epoch 94/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3633 - accuracy: 0.8277\n",
            "Epoch 95/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3631 - accuracy: 0.8268\n",
            "Epoch 96/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3628 - accuracy: 0.8292\n",
            "Epoch 97/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3624 - accuracy: 0.8256\n",
            "Epoch 98/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3621 - accuracy: 0.8274\n",
            "Epoch 99/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3624 - accuracy: 0.8272\n",
            "Epoch 100/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 0.3615 - accuracy: 0.8281\n",
            "29/44 [==================>...........] - ETA: 0s - loss: 0.4648 - accuracy: 0.7953"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-02-01 16:31:01.009463: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "44/44 [==============================] - 0s 4ms/step - loss: 0.4719 - accuracy: 0.7875\n",
            "[0.47188180685043335, 0.7874911427497864]\n",
            "Classification Report: -                precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.87      0.86      1038\n",
            "           1       0.61      0.54      0.57       369\n",
            "\n",
            "    accuracy                           0.79      1407\n",
            "   macro avg       0.72      0.71      0.72      1407\n",
            "weighted avg       0.78      0.79      0.78      1407\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-02-01 16:31:01.266846: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        }
      ],
      "source": [
        "y_pred = ANN(x_train, y_train, x_test, y_test, 'binary_crossentropy', -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    1038\n",
              "1     369\n",
              "Name: Churn, dtype: int64"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "# We get a imbalance in the dataset here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5163 1869\n"
          ]
        }
      ],
      "source": [
        "df_churn_0 = df2[df2['Churn'] == 0]\n",
        "df_churn_1 = df2[df2['Churn'] == 1]\n",
        "\n",
        "print(len(df_churn_0), len(df_churn_1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_churn_0_under = df_churn_0.sample(len(df_churn_1))\n",
        "\n",
        "#making the whole dataset\n",
        "#mixing 1869 entries of churn == 0 with 1869 entries of churn == 1\n",
        "\n",
        "df_under_final = pd.concat([df_churn_0_under, df_churn_1], axis = 'rows')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3738, 27)"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_under_final.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## making the training and testing dataset to train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = df_under_final.drop('Churn', axis = 'columns')\n",
        "y = df_under_final['Churn']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2990, 26)"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(748, 26)"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2990,)"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(748,)"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-02-01 19:28:13.489299: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "94/94 [==============================] - 1s 10ms/step - loss: 0.6234 - accuracy: 0.6696\n",
            "Epoch 2/100\n",
            "94/94 [==============================] - 1s 7ms/step - loss: 0.5201 - accuracy: 0.7555\n",
            "Epoch 3/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4965 - accuracy: 0.7669\n",
            "Epoch 4/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4886 - accuracy: 0.7689\n",
            "Epoch 5/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4836 - accuracy: 0.7749\n",
            "Epoch 6/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4810 - accuracy: 0.7759\n",
            "Epoch 7/100\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.4785 - accuracy: 0.7722\n",
            "Epoch 8/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4755 - accuracy: 0.7742\n",
            "Epoch 9/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4748 - accuracy: 0.7776\n",
            "Epoch 10/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4727 - accuracy: 0.7753\n",
            "Epoch 11/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4697 - accuracy: 0.7763\n",
            "Epoch 12/100\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.4680 - accuracy: 0.7776\n",
            "Epoch 13/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4666 - accuracy: 0.7729\n",
            "Epoch 14/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4645 - accuracy: 0.7809\n",
            "Epoch 15/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4625 - accuracy: 0.7799\n",
            "Epoch 16/100\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.4616 - accuracy: 0.7799\n",
            "Epoch 17/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4605 - accuracy: 0.7813\n",
            "Epoch 18/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4586 - accuracy: 0.7803\n",
            "Epoch 19/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4582 - accuracy: 0.7826\n",
            "Epoch 20/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4559 - accuracy: 0.7833\n",
            "Epoch 21/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4549 - accuracy: 0.7829\n",
            "Epoch 22/100\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.4531 - accuracy: 0.7866\n",
            "Epoch 23/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4523 - accuracy: 0.7849\n",
            "Epoch 24/100\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.4503 - accuracy: 0.7893\n",
            "Epoch 25/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4499 - accuracy: 0.7860\n",
            "Epoch 26/100\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.4500 - accuracy: 0.7849\n",
            "Epoch 27/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4479 - accuracy: 0.7870\n",
            "Epoch 28/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4482 - accuracy: 0.7839\n",
            "Epoch 29/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4469 - accuracy: 0.7856\n",
            "Epoch 30/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4451 - accuracy: 0.7926\n",
            "Epoch 31/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4434 - accuracy: 0.7906\n",
            "Epoch 32/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4429 - accuracy: 0.7913\n",
            "Epoch 33/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4425 - accuracy: 0.7900\n",
            "Epoch 34/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4432 - accuracy: 0.7900\n",
            "Epoch 35/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4405 - accuracy: 0.7893\n",
            "Epoch 36/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4393 - accuracy: 0.7930\n",
            "Epoch 37/100\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.4392 - accuracy: 0.7903\n",
            "Epoch 38/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4376 - accuracy: 0.7873\n",
            "Epoch 39/100\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.4372 - accuracy: 0.7920\n",
            "Epoch 40/100\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.4370 - accuracy: 0.7900\n",
            "Epoch 41/100\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.4354 - accuracy: 0.7906\n",
            "Epoch 42/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4335 - accuracy: 0.7923\n",
            "Epoch 43/100\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.4344 - accuracy: 0.7920\n",
            "Epoch 44/100\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.4341 - accuracy: 0.7926\n",
            "Epoch 45/100\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.4325 - accuracy: 0.7957\n",
            "Epoch 46/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4315 - accuracy: 0.7930\n",
            "Epoch 47/100\n",
            "94/94 [==============================] - 1s 8ms/step - loss: 0.4311 - accuracy: 0.7950\n",
            "Epoch 48/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4316 - accuracy: 0.7916\n",
            "Epoch 49/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4293 - accuracy: 0.7970\n",
            "Epoch 50/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4282 - accuracy: 0.7926\n",
            "Epoch 51/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4276 - accuracy: 0.8000\n",
            "Epoch 52/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4272 - accuracy: 0.7973\n",
            "Epoch 53/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4251 - accuracy: 0.7993\n",
            "Epoch 54/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4270 - accuracy: 0.7983\n",
            "Epoch 55/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4248 - accuracy: 0.7963\n",
            "Epoch 56/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4262 - accuracy: 0.7980\n",
            "Epoch 57/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4232 - accuracy: 0.8010\n",
            "Epoch 58/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4238 - accuracy: 0.7940\n",
            "Epoch 59/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4245 - accuracy: 0.7977\n",
            "Epoch 60/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4231 - accuracy: 0.8027\n",
            "Epoch 61/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4217 - accuracy: 0.8030\n",
            "Epoch 62/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4213 - accuracy: 0.7963\n",
            "Epoch 63/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4197 - accuracy: 0.8054\n",
            "Epoch 64/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4192 - accuracy: 0.8020\n",
            "Epoch 65/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4177 - accuracy: 0.7983\n",
            "Epoch 66/100\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.4176 - accuracy: 0.8043\n",
            "Epoch 67/100\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.4170 - accuracy: 0.8040\n",
            "Epoch 68/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4174 - accuracy: 0.8013\n",
            "Epoch 69/100\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.4157 - accuracy: 0.8023\n",
            "Epoch 70/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4154 - accuracy: 0.8050\n",
            "Epoch 71/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4136 - accuracy: 0.8057\n",
            "Epoch 72/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4136 - accuracy: 0.8033\n",
            "Epoch 73/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4121 - accuracy: 0.8043\n",
            "Epoch 74/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4119 - accuracy: 0.8020\n",
            "Epoch 75/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.8080\n",
            "Epoch 76/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4158 - accuracy: 0.8043\n",
            "Epoch 77/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8064\n",
            "Epoch 78/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4085 - accuracy: 0.8047\n",
            "Epoch 79/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.8077\n",
            "Epoch 80/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4083 - accuracy: 0.8060\n",
            "Epoch 81/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4092 - accuracy: 0.8100\n",
            "Epoch 82/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4080 - accuracy: 0.8094\n",
            "Epoch 83/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4100 - accuracy: 0.8097\n",
            "Epoch 84/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.8144\n",
            "Epoch 85/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4049 - accuracy: 0.8107\n",
            "Epoch 86/100\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.4057 - accuracy: 0.8124\n",
            "Epoch 87/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4030 - accuracy: 0.8127\n",
            "Epoch 88/100\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.4032 - accuracy: 0.8094\n",
            "Epoch 89/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4038 - accuracy: 0.8090\n",
            "Epoch 90/100\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.4029 - accuracy: 0.8127\n",
            "Epoch 91/100\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.4005 - accuracy: 0.8134\n",
            "Epoch 92/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4000 - accuracy: 0.8130\n",
            "Epoch 93/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8151\n",
            "Epoch 94/100\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.3990 - accuracy: 0.8137\n",
            "Epoch 95/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4006 - accuracy: 0.8127\n",
            "Epoch 96/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.8151\n",
            "Epoch 97/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4000 - accuracy: 0.8137\n",
            "Epoch 98/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.3970 - accuracy: 0.8181\n",
            "Epoch 99/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.3949 - accuracy: 0.8164\n",
            "Epoch 100/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8177\n",
            "14/24 [================>.............] - ETA: 0s - loss: 0.5290 - accuracy: 0.7478"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-02-01 19:29:05.339044: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 0s 8ms/step - loss: 0.5403 - accuracy: 0.7433\n",
            "[0.540282666683197, 0.7433155179023743]\n",
            "Classification Report: -                precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.76      0.75       374\n",
            "           1       0.75      0.73      0.74       374\n",
            "\n",
            "    accuracy                           0.74       748\n",
            "   macro avg       0.74      0.74      0.74       748\n",
            "weighted avg       0.74      0.74      0.74       748\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-02-01 19:29:05.617349: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        }
      ],
      "source": [
        "y_pred = ANN(x_train, y_train, x_test, y_test, 'binary_crossentropy', -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    1869\n",
              "1    1869\n",
              "Name: Churn, dtype: int64"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_under_final.Churn.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1    1495\n",
              "0    1495\n",
              "Name: Churn, dtype: int64"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Treating imbalance with oversampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5163 1869\n"
          ]
        }
      ],
      "source": [
        "print(len(df_churn_0), len(df_churn_1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_churn_1_oversampling = df_churn_1.sample(len(df_churn_0), replace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5163, 27)"
            ]
          },
          "execution_count": 120,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_churn_1_oversampling.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [],
      "source": [
        "#making the oversampled churn_1 dataframe and churn_0 dataframe in one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_oversampling = pd.concat([df_churn_1_oversampling,df_churn_0], axis = 'rows')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10326, 27)"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_oversampling.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = df_oversampling.drop('Churn', axis = 'columns')\n",
        "y = df_oversampling.Churn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "  1/259 [..............................] - ETA: 1:17 - loss: 0.7300 - accuracy: 0.4062"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-02-01 23:13:20.635745: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "259/259 [==============================] - 2s 6ms/step - loss: 0.5422 - accuracy: 0.7362\n",
            "Epoch 2/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.4716 - accuracy: 0.7769\n",
            "Epoch 3/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.4620 - accuracy: 0.7815\n",
            "Epoch 4/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.4574 - accuracy: 0.7827\n",
            "Epoch 5/100\n",
            "259/259 [==============================] - 2s 6ms/step - loss: 0.4525 - accuracy: 0.7827\n",
            "Epoch 6/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.4477 - accuracy: 0.7835\n",
            "Epoch 7/100\n",
            "259/259 [==============================] - 2s 6ms/step - loss: 0.4450 - accuracy: 0.7864\n",
            "Epoch 8/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.4392 - accuracy: 0.7918\n",
            "Epoch 9/100\n",
            "259/259 [==============================] - 1s 6ms/step - loss: 0.4364 - accuracy: 0.7948\n",
            "Epoch 10/100\n",
            "259/259 [==============================] - 2s 6ms/step - loss: 0.4324 - accuracy: 0.7952\n",
            "Epoch 11/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.4299 - accuracy: 0.7970\n",
            "Epoch 12/100\n",
            "259/259 [==============================] - 2s 6ms/step - loss: 0.4265 - accuracy: 0.7994\n",
            "Epoch 13/100\n",
            "259/259 [==============================] - 1s 6ms/step - loss: 0.4228 - accuracy: 0.8018\n",
            "Epoch 14/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.4208 - accuracy: 0.8025\n",
            "Epoch 15/100\n",
            "259/259 [==============================] - 2s 6ms/step - loss: 0.4158 - accuracy: 0.8050\n",
            "Epoch 16/100\n",
            "259/259 [==============================] - 2s 6ms/step - loss: 0.4142 - accuracy: 0.8057\n",
            "Epoch 17/100\n",
            "259/259 [==============================] - 2s 6ms/step - loss: 0.4104 - accuracy: 0.8085\n",
            "Epoch 18/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.4078 - accuracy: 0.8123\n",
            "Epoch 19/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.4062 - accuracy: 0.8120\n",
            "Epoch 20/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.4032 - accuracy: 0.8121\n",
            "Epoch 21/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.4010 - accuracy: 0.8162\n",
            "Epoch 22/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3979 - accuracy: 0.8172\n",
            "Epoch 23/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3966 - accuracy: 0.8195\n",
            "Epoch 24/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3934 - accuracy: 0.8183\n",
            "Epoch 25/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3923 - accuracy: 0.8207\n",
            "Epoch 26/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3910 - accuracy: 0.8234\n",
            "Epoch 27/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3893 - accuracy: 0.8232\n",
            "Epoch 28/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3872 - accuracy: 0.8231\n",
            "Epoch 29/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3847 - accuracy: 0.8253\n",
            "Epoch 30/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3834 - accuracy: 0.8247\n",
            "Epoch 31/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3841 - accuracy: 0.8257\n",
            "Epoch 32/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3810 - accuracy: 0.8251\n",
            "Epoch 33/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3794 - accuracy: 0.8282\n",
            "Epoch 34/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3799 - accuracy: 0.8280\n",
            "Epoch 35/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3781 - accuracy: 0.8304\n",
            "Epoch 36/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3755 - accuracy: 0.8304\n",
            "Epoch 37/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3756 - accuracy: 0.8309\n",
            "Epoch 38/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3744 - accuracy: 0.8299\n",
            "Epoch 39/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3739 - accuracy: 0.8329\n",
            "Epoch 40/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3719 - accuracy: 0.8327\n",
            "Epoch 41/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3726 - accuracy: 0.8310\n",
            "Epoch 42/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3708 - accuracy: 0.8345\n",
            "Epoch 43/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3682 - accuracy: 0.8390\n",
            "Epoch 44/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3677 - accuracy: 0.8351\n",
            "Epoch 45/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3680 - accuracy: 0.8328\n",
            "Epoch 46/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3669 - accuracy: 0.8351\n",
            "Epoch 47/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3663 - accuracy: 0.8346\n",
            "Epoch 48/100\n",
            "259/259 [==============================] - 2s 7ms/step - loss: 0.3647 - accuracy: 0.8391\n",
            "Epoch 49/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3647 - accuracy: 0.8367\n",
            "Epoch 50/100\n",
            "259/259 [==============================] - 1s 6ms/step - loss: 0.3632 - accuracy: 0.8392\n",
            "Epoch 51/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3611 - accuracy: 0.8393\n",
            "Epoch 52/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3612 - accuracy: 0.8354\n",
            "Epoch 53/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3598 - accuracy: 0.8401\n",
            "Epoch 54/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3612 - accuracy: 0.8378\n",
            "Epoch 55/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3598 - accuracy: 0.8393\n",
            "Epoch 56/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3590 - accuracy: 0.8406\n",
            "Epoch 57/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3595 - accuracy: 0.8378\n",
            "Epoch 58/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3575 - accuracy: 0.8404\n",
            "Epoch 59/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3571 - accuracy: 0.8415\n",
            "Epoch 60/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3554 - accuracy: 0.8415\n",
            "Epoch 61/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3543 - accuracy: 0.8427\n",
            "Epoch 62/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3555 - accuracy: 0.8413\n",
            "Epoch 63/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3542 - accuracy: 0.8429\n",
            "Epoch 64/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3520 - accuracy: 0.8447\n",
            "Epoch 65/100\n",
            "259/259 [==============================] - 1s 6ms/step - loss: 0.3505 - accuracy: 0.8459\n",
            "Epoch 66/100\n",
            "259/259 [==============================] - 1s 6ms/step - loss: 0.3550 - accuracy: 0.8431\n",
            "Epoch 67/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3507 - accuracy: 0.8435\n",
            "Epoch 68/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3508 - accuracy: 0.8443\n",
            "Epoch 69/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3499 - accuracy: 0.8465\n",
            "Epoch 70/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3499 - accuracy: 0.8449\n",
            "Epoch 71/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3488 - accuracy: 0.8469\n",
            "Epoch 72/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3481 - accuracy: 0.8439\n",
            "Epoch 73/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3486 - accuracy: 0.8436\n",
            "Epoch 74/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3502 - accuracy: 0.8450\n",
            "Epoch 75/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3477 - accuracy: 0.8453\n",
            "Epoch 76/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3454 - accuracy: 0.8460\n",
            "Epoch 77/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3465 - accuracy: 0.8460\n",
            "Epoch 78/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3455 - accuracy: 0.8460\n",
            "Epoch 79/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3459 - accuracy: 0.8485\n",
            "Epoch 80/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3451 - accuracy: 0.8492\n",
            "Epoch 81/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3440 - accuracy: 0.8471\n",
            "Epoch 82/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3435 - accuracy: 0.8490\n",
            "Epoch 83/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3425 - accuracy: 0.8492\n",
            "Epoch 84/100\n",
            "259/259 [==============================] - 2s 6ms/step - loss: 0.3457 - accuracy: 0.8487\n",
            "Epoch 85/100\n",
            "259/259 [==============================] - 2s 7ms/step - loss: 0.3422 - accuracy: 0.8482\n",
            "Epoch 86/100\n",
            "259/259 [==============================] - 2s 6ms/step - loss: 0.3428 - accuracy: 0.8504\n",
            "Epoch 87/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3425 - accuracy: 0.8453\n",
            "Epoch 88/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3394 - accuracy: 0.8511\n",
            "Epoch 89/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3425 - accuracy: 0.8449\n",
            "Epoch 90/100\n",
            "259/259 [==============================] - 2s 6ms/step - loss: 0.3411 - accuracy: 0.8475\n",
            "Epoch 91/100\n",
            "259/259 [==============================] - 2s 7ms/step - loss: 0.3418 - accuracy: 0.8527\n",
            "Epoch 92/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3409 - accuracy: 0.8481\n",
            "Epoch 93/100\n",
            "259/259 [==============================] - 2s 6ms/step - loss: 0.3405 - accuracy: 0.8489\n",
            "Epoch 94/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3388 - accuracy: 0.8519\n",
            "Epoch 95/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3385 - accuracy: 0.8536\n",
            "Epoch 96/100\n",
            "259/259 [==============================] - 1s 6ms/step - loss: 0.3389 - accuracy: 0.8527\n",
            "Epoch 97/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3378 - accuracy: 0.8535\n",
            "Epoch 98/100\n",
            "259/259 [==============================] - 2s 6ms/step - loss: 0.3384 - accuracy: 0.8512\n",
            "Epoch 99/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3396 - accuracy: 0.8525\n",
            "Epoch 100/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3369 - accuracy: 0.8511\n",
            "28/65 [===========>..................] - ETA: 0s - loss: 0.4095 - accuracy: 0.8103"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-02-01 23:15:39.872751: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "65/65 [==============================] - 0s 4ms/step - loss: 0.4101 - accuracy: 0.8180\n",
            "[0.4101164937019348, 0.8180058002471924]\n",
            "Classification Report: - \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.78      0.81      1033\n",
            "           1       0.80      0.85      0.82      1033\n",
            "\n",
            "    accuracy                           0.82      2066\n",
            "   macro avg       0.82      0.82      0.82      2066\n",
            "weighted avg       0.82      0.82      0.82      2066\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-02-01 23:15:40.224080: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        }
      ],
      "source": [
        "y_pred = ANN(x_train, y_train, x_test, y_test, 'binary_crossentropy', -1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Treating Imbalance dataset with SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = df2.drop('Churn', axis = 'columns')\n",
        "y = df2['Churn']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    5163\n",
              "1    5163\n",
              "Name: Churn, dtype: int64"
            ]
          },
          "execution_count": 146,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "smote = SMOTE(sampling_strategy = 'minority')\n",
        "x, y = smote.fit_resample(x,y)\n",
        "y.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1    4130\n",
              "0    4130\n",
              "Name: Churn, dtype: int64"
            ]
          },
          "execution_count": 152,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    1033\n",
              "1    1033\n",
              "Name: Churn, dtype: int64"
            ]
          },
          "execution_count": 153,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "  1/259 [..............................] - ETA: 1:06 - loss: 0.7052 - accuracy: 0.5000"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-02-01 23:15:58.396901: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "259/259 [==============================] - 2s 5ms/step - loss: 0.5394 - accuracy: 0.7345\n",
            "Epoch 2/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.4722 - accuracy: 0.7759\n",
            "Epoch 3/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.4608 - accuracy: 0.7809\n",
            "Epoch 4/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.4556 - accuracy: 0.7821\n",
            "Epoch 5/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.4515 - accuracy: 0.7826\n",
            "Epoch 6/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.4475 - accuracy: 0.7878\n",
            "Epoch 7/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.4425 - accuracy: 0.7891\n",
            "Epoch 8/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.4386 - accuracy: 0.7918\n",
            "Epoch 9/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.4350 - accuracy: 0.7927\n",
            "Epoch 10/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.4317 - accuracy: 0.7959\n",
            "Epoch 11/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.4281 - accuracy: 0.8012\n",
            "Epoch 12/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.4252 - accuracy: 0.8002\n",
            "Epoch 13/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.4232 - accuracy: 0.8022\n",
            "Epoch 14/100\n",
            "259/259 [==============================] - 2s 6ms/step - loss: 0.4192 - accuracy: 0.8036\n",
            "Epoch 15/100\n",
            "259/259 [==============================] - 1s 6ms/step - loss: 0.4163 - accuracy: 0.8063\n",
            "Epoch 16/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.4132 - accuracy: 0.8096\n",
            "Epoch 17/100\n",
            "259/259 [==============================] - 2s 7ms/step - loss: 0.4108 - accuracy: 0.8121\n",
            "Epoch 18/100\n",
            "259/259 [==============================] - 2s 7ms/step - loss: 0.4077 - accuracy: 0.8110\n",
            "Epoch 19/100\n",
            "259/259 [==============================] - 2s 7ms/step - loss: 0.4054 - accuracy: 0.8111\n",
            "Epoch 20/100\n",
            "259/259 [==============================] - 2s 6ms/step - loss: 0.4046 - accuracy: 0.8151\n",
            "Epoch 21/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.4049 - accuracy: 0.8115\n",
            "Epoch 22/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3986 - accuracy: 0.8165\n",
            "Epoch 23/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3988 - accuracy: 0.8178\n",
            "Epoch 24/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3952 - accuracy: 0.8209\n",
            "Epoch 25/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3942 - accuracy: 0.8207\n",
            "Epoch 26/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3945 - accuracy: 0.8217\n",
            "Epoch 27/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3910 - accuracy: 0.8213\n",
            "Epoch 28/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3913 - accuracy: 0.8252\n",
            "Epoch 29/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3878 - accuracy: 0.8234\n",
            "Epoch 30/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3869 - accuracy: 0.8238\n",
            "Epoch 31/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3852 - accuracy: 0.8254\n",
            "Epoch 32/100\n",
            "259/259 [==============================] - 1s 6ms/step - loss: 0.3868 - accuracy: 0.8240\n",
            "Epoch 33/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3826 - accuracy: 0.8258\n",
            "Epoch 34/100\n",
            "259/259 [==============================] - 2s 6ms/step - loss: 0.3837 - accuracy: 0.8270\n",
            "Epoch 35/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3809 - accuracy: 0.8298\n",
            "Epoch 36/100\n",
            "259/259 [==============================] - 2s 6ms/step - loss: 0.3794 - accuracy: 0.8334\n",
            "Epoch 37/100\n",
            "259/259 [==============================] - 2s 6ms/step - loss: 0.3796 - accuracy: 0.8300\n",
            "Epoch 38/100\n",
            "259/259 [==============================] - 1s 6ms/step - loss: 0.3762 - accuracy: 0.8318\n",
            "Epoch 39/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3758 - accuracy: 0.8346\n",
            "Epoch 40/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3753 - accuracy: 0.8341\n",
            "Epoch 41/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3751 - accuracy: 0.8304\n",
            "Epoch 42/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3735 - accuracy: 0.8329\n",
            "Epoch 43/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3737 - accuracy: 0.8345\n",
            "Epoch 44/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3716 - accuracy: 0.8351\n",
            "Epoch 45/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3706 - accuracy: 0.8354\n",
            "Epoch 46/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3719 - accuracy: 0.8331\n",
            "Epoch 47/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3684 - accuracy: 0.8390\n",
            "Epoch 48/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3672 - accuracy: 0.8389\n",
            "Epoch 49/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3669 - accuracy: 0.8368\n",
            "Epoch 50/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3677 - accuracy: 0.8363\n",
            "Epoch 51/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3671 - accuracy: 0.8366\n",
            "Epoch 52/100\n",
            "259/259 [==============================] - 1s 6ms/step - loss: 0.3639 - accuracy: 0.8397\n",
            "Epoch 53/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3676 - accuracy: 0.8370\n",
            "Epoch 54/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3648 - accuracy: 0.8387\n",
            "Epoch 55/100\n",
            "259/259 [==============================] - 2s 6ms/step - loss: 0.3626 - accuracy: 0.8392\n",
            "Epoch 56/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3640 - accuracy: 0.8383\n",
            "Epoch 57/100\n",
            "259/259 [==============================] - 2s 6ms/step - loss: 0.3619 - accuracy: 0.8400\n",
            "Epoch 58/100\n",
            "259/259 [==============================] - 2s 6ms/step - loss: 0.3608 - accuracy: 0.8410\n",
            "Epoch 59/100\n",
            "259/259 [==============================] - 2s 6ms/step - loss: 0.3616 - accuracy: 0.8393\n",
            "Epoch 60/100\n",
            "259/259 [==============================] - 1s 6ms/step - loss: 0.3600 - accuracy: 0.8395\n",
            "Epoch 61/100\n",
            "259/259 [==============================] - 2s 7ms/step - loss: 0.3590 - accuracy: 0.8421\n",
            "Epoch 62/100\n",
            "259/259 [==============================] - 2s 6ms/step - loss: 0.3571 - accuracy: 0.8425\n",
            "Epoch 63/100\n",
            "259/259 [==============================] - 2s 6ms/step - loss: 0.3570 - accuracy: 0.8408\n",
            "Epoch 64/100\n",
            "259/259 [==============================] - 2s 6ms/step - loss: 0.3556 - accuracy: 0.8421\n",
            "Epoch 65/100\n",
            "259/259 [==============================] - 2s 7ms/step - loss: 0.3592 - accuracy: 0.8423\n",
            "Epoch 66/100\n",
            "259/259 [==============================] - 2s 6ms/step - loss: 0.3536 - accuracy: 0.8426\n",
            "Epoch 67/100\n",
            "259/259 [==============================] - 2s 6ms/step - loss: 0.3566 - accuracy: 0.8395\n",
            "Epoch 68/100\n",
            "259/259 [==============================] - 2s 6ms/step - loss: 0.3542 - accuracy: 0.8438\n",
            "Epoch 69/100\n",
            "259/259 [==============================] - 2s 6ms/step - loss: 0.3556 - accuracy: 0.8424\n",
            "Epoch 70/100\n",
            "259/259 [==============================] - 2s 6ms/step - loss: 0.3523 - accuracy: 0.8427\n",
            "Epoch 71/100\n",
            "259/259 [==============================] - 2s 6ms/step - loss: 0.3591 - accuracy: 0.8391\n",
            "Epoch 72/100\n",
            "259/259 [==============================] - 2s 6ms/step - loss: 0.3529 - accuracy: 0.8455\n",
            "Epoch 73/100\n",
            "259/259 [==============================] - 2s 6ms/step - loss: 0.3516 - accuracy: 0.8449\n",
            "Epoch 74/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3510 - accuracy: 0.8454\n",
            "Epoch 75/100\n",
            "259/259 [==============================] - 1s 6ms/step - loss: 0.3501 - accuracy: 0.8438\n",
            "Epoch 76/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3525 - accuracy: 0.8444\n",
            "Epoch 77/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3495 - accuracy: 0.8470\n",
            "Epoch 78/100\n",
            "259/259 [==============================] - 2s 6ms/step - loss: 0.3501 - accuracy: 0.8461\n",
            "Epoch 79/100\n",
            "259/259 [==============================] - 1s 6ms/step - loss: 0.3472 - accuracy: 0.8473\n",
            "Epoch 80/100\n",
            "259/259 [==============================] - 2s 6ms/step - loss: 0.3494 - accuracy: 0.8469\n",
            "Epoch 81/100\n",
            "259/259 [==============================] - 2s 6ms/step - loss: 0.3474 - accuracy: 0.8414\n",
            "Epoch 82/100\n",
            "259/259 [==============================] - 2s 6ms/step - loss: 0.3483 - accuracy: 0.8466\n",
            "Epoch 83/100\n",
            "259/259 [==============================] - 2s 6ms/step - loss: 0.3459 - accuracy: 0.8504\n",
            "Epoch 84/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3471 - accuracy: 0.8454\n",
            "Epoch 85/100\n",
            "259/259 [==============================] - 1s 6ms/step - loss: 0.3480 - accuracy: 0.8479\n",
            "Epoch 86/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3467 - accuracy: 0.8461\n",
            "Epoch 87/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3469 - accuracy: 0.8476\n",
            "Epoch 88/100\n",
            "259/259 [==============================] - 1s 6ms/step - loss: 0.3451 - accuracy: 0.8479\n",
            "Epoch 89/100\n",
            "259/259 [==============================] - 2s 6ms/step - loss: 0.3452 - accuracy: 0.8505\n",
            "Epoch 90/100\n",
            "259/259 [==============================] - 2s 7ms/step - loss: 0.3438 - accuracy: 0.8494\n",
            "Epoch 91/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3423 - accuracy: 0.8489\n",
            "Epoch 92/100\n",
            "259/259 [==============================] - 2s 6ms/step - loss: 0.3435 - accuracy: 0.8501\n",
            "Epoch 93/100\n",
            "259/259 [==============================] - 2s 6ms/step - loss: 0.3435 - accuracy: 0.8515\n",
            "Epoch 94/100\n",
            "259/259 [==============================] - 2s 7ms/step - loss: 0.3417 - accuracy: 0.8492\n",
            "Epoch 95/100\n",
            "259/259 [==============================] - 2s 7ms/step - loss: 0.3428 - accuracy: 0.8479\n",
            "Epoch 96/100\n",
            "259/259 [==============================] - 2s 6ms/step - loss: 0.3412 - accuracy: 0.8484\n",
            "Epoch 97/100\n",
            "259/259 [==============================] - 1s 6ms/step - loss: 0.3393 - accuracy: 0.8521\n",
            "Epoch 98/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3403 - accuracy: 0.8479\n",
            "Epoch 99/100\n",
            "259/259 [==============================] - 1s 6ms/step - loss: 0.3433 - accuracy: 0.8512\n",
            "Epoch 100/100\n",
            "259/259 [==============================] - 1s 5ms/step - loss: 0.3428 - accuracy: 0.8478\n",
            "31/65 [=============>................] - ETA: 0s - loss: 0.4011 - accuracy: 0.8185"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-02-01 23:18:25.858420: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "65/65 [==============================] - 0s 4ms/step - loss: 0.4100 - accuracy: 0.8156\n",
            "[0.41000887751579285, 0.8155856728553772]\n",
            "Classification Report: - \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.80      1033\n",
            "           1       0.78      0.87      0.83      1033\n",
            "\n",
            "    accuracy                           0.82      2066\n",
            "   macro avg       0.82      0.82      0.81      2066\n",
            "weighted avg       0.82      0.82      0.81      2066\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-02-01 23:18:26.183670: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        }
      ],
      "source": [
        "y_pred = ANN(x_train, y_train, x_test, y_test, 'binary_crossentropy', -1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Teating dataset imbalance with Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = df2.drop('Churn', axis = 'columns')\n",
        "y = df2.Churn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    5163\n",
              "1    1869\n",
              "Name: Churn, dtype: int64"
            ]
          },
          "execution_count": 159,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    4130\n",
              "1    1495\n",
              "Name: Churn, dtype: int64"
            ]
          },
          "execution_count": 161,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2.762541806020067"
            ]
          },
          "execution_count": 162,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "4130/1495"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "model1 --> class1(1495) + class0(0, 1495)\n",
        "\n",
        "model2 --> class1(1495) + class0(1496, 2990)\n",
        "\n",
        "model3 --> class1(1495) + class0(2990, 4130)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {},
      "outputs": [],
      "source": [
        "df3 = x_train.copy()\n",
        "df3['Churn'] = y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {},
      "outputs": [],
      "source": [
        "df3_0 = df3[df3.Churn == 0]\n",
        "df3_1 = df3[df3.Churn == 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {},
      "outputs": [],
      "source": [
        "def training_batch(majority, minority, start, end):\n",
        "    df_training_batch = pd.concat([majority[start:end], minority], axis = 'rows')\n",
        "\n",
        "    x_train = df_training_batch.drop('Churn', axis = 'columns')\n",
        "    y_train = df_training_batch.Churn\n",
        "\n",
        "    return x_train, y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-02-02 01:09:28.399921: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "94/94 [==============================] - 1s 6ms/step - loss: 0.6222 - accuracy: 0.6712\n",
            "Epoch 2/100\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.5178 - accuracy: 0.7475\n",
            "Epoch 3/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4920 - accuracy: 0.7645\n",
            "Epoch 4/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4823 - accuracy: 0.7742\n",
            "Epoch 5/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4758 - accuracy: 0.7759\n",
            "Epoch 6/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4718 - accuracy: 0.7796\n",
            "Epoch 7/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4688 - accuracy: 0.7793\n",
            "Epoch 8/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4660 - accuracy: 0.7826\n",
            "Epoch 9/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4628 - accuracy: 0.7833\n",
            "Epoch 10/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4622 - accuracy: 0.7836\n",
            "Epoch 11/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4589 - accuracy: 0.7853\n",
            "Epoch 12/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4582 - accuracy: 0.7860\n",
            "Epoch 13/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4562 - accuracy: 0.7903\n",
            "Epoch 14/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4543 - accuracy: 0.7870\n",
            "Epoch 15/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4552 - accuracy: 0.7900\n",
            "Epoch 16/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4520 - accuracy: 0.7910\n",
            "Epoch 17/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4506 - accuracy: 0.7880\n",
            "Epoch 18/100\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.4477 - accuracy: 0.7906\n",
            "Epoch 19/100\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.4477 - accuracy: 0.7883\n",
            "Epoch 20/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4454 - accuracy: 0.7903\n",
            "Epoch 21/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4438 - accuracy: 0.7933\n",
            "Epoch 22/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4437 - accuracy: 0.7903\n",
            "Epoch 23/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4429 - accuracy: 0.7906\n",
            "Epoch 24/100\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.4411 - accuracy: 0.7980\n",
            "Epoch 25/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4391 - accuracy: 0.7983\n",
            "Epoch 26/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4378 - accuracy: 0.7973\n",
            "Epoch 27/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4375 - accuracy: 0.7967\n",
            "Epoch 28/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4353 - accuracy: 0.7987\n",
            "Epoch 29/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4338 - accuracy: 0.8043\n",
            "Epoch 30/100\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.4334 - accuracy: 0.7987\n",
            "Epoch 31/100\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.4328 - accuracy: 0.7993\n",
            "Epoch 32/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4306 - accuracy: 0.7990\n",
            "Epoch 33/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4302 - accuracy: 0.7997\n",
            "Epoch 34/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4312 - accuracy: 0.7973\n",
            "Epoch 35/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4288 - accuracy: 0.8047\n",
            "Epoch 36/100\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.4274 - accuracy: 0.8067\n",
            "Epoch 37/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4259 - accuracy: 0.8023\n",
            "Epoch 38/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4229 - accuracy: 0.8057\n",
            "Epoch 39/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4232 - accuracy: 0.8023\n",
            "Epoch 40/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.8020\n",
            "Epoch 41/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4223 - accuracy: 0.8080\n",
            "Epoch 42/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4193 - accuracy: 0.8047\n",
            "Epoch 43/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4181 - accuracy: 0.8050\n",
            "Epoch 44/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4174 - accuracy: 0.8060\n",
            "Epoch 45/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4173 - accuracy: 0.8057\n",
            "Epoch 46/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4152 - accuracy: 0.8060\n",
            "Epoch 47/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4149 - accuracy: 0.8114\n",
            "Epoch 48/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4124 - accuracy: 0.8057\n",
            "Epoch 49/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4115 - accuracy: 0.8124\n",
            "Epoch 50/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4124 - accuracy: 0.8097\n",
            "Epoch 51/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4095 - accuracy: 0.8114\n",
            "Epoch 52/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4073 - accuracy: 0.8134\n",
            "Epoch 53/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.8124\n",
            "Epoch 54/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4070 - accuracy: 0.8097\n",
            "Epoch 55/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4050 - accuracy: 0.8144\n",
            "Epoch 56/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4042 - accuracy: 0.8107\n",
            "Epoch 57/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4024 - accuracy: 0.8147\n",
            "Epoch 58/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4028 - accuracy: 0.8120\n",
            "Epoch 59/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4018 - accuracy: 0.8147\n",
            "Epoch 60/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.3995 - accuracy: 0.8157\n",
            "Epoch 61/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.3992 - accuracy: 0.8164\n",
            "Epoch 62/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.3995 - accuracy: 0.8194\n",
            "Epoch 63/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.3957 - accuracy: 0.8184\n",
            "Epoch 64/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.3954 - accuracy: 0.8174\n",
            "Epoch 65/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.3945 - accuracy: 0.8134\n",
            "Epoch 66/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.3956 - accuracy: 0.8140\n",
            "Epoch 67/100\n",
            "94/94 [==============================] - 1s 7ms/step - loss: 0.3929 - accuracy: 0.8161\n",
            "Epoch 68/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.3916 - accuracy: 0.8221\n",
            "Epoch 69/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.3910 - accuracy: 0.8191\n",
            "Epoch 70/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.3887 - accuracy: 0.8181\n",
            "Epoch 71/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.3903 - accuracy: 0.8217\n",
            "Epoch 72/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.3872 - accuracy: 0.8214\n",
            "Epoch 73/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.3870 - accuracy: 0.8187\n",
            "Epoch 74/100\n",
            "94/94 [==============================] - 1s 7ms/step - loss: 0.3863 - accuracy: 0.8268\n",
            "Epoch 75/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.3859 - accuracy: 0.8251\n",
            "Epoch 76/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.3867 - accuracy: 0.8201\n",
            "Epoch 77/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.3826 - accuracy: 0.8231\n",
            "Epoch 78/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.3822 - accuracy: 0.8181\n",
            "Epoch 79/100\n",
            "94/94 [==============================] - 1s 7ms/step - loss: 0.3832 - accuracy: 0.8241\n",
            "Epoch 80/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.3817 - accuracy: 0.8234\n",
            "Epoch 81/100\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.3810 - accuracy: 0.8231\n",
            "Epoch 82/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.3786 - accuracy: 0.8237\n",
            "Epoch 83/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.3816 - accuracy: 0.8254\n",
            "Epoch 84/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.3787 - accuracy: 0.8298\n",
            "Epoch 85/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.3794 - accuracy: 0.8227\n",
            "Epoch 86/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.3769 - accuracy: 0.8258\n",
            "Epoch 87/100\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.3780 - accuracy: 0.8261\n",
            "Epoch 88/100\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.3750 - accuracy: 0.8301\n",
            "Epoch 89/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.3741 - accuracy: 0.8261\n",
            "Epoch 90/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.3743 - accuracy: 0.8268\n",
            "Epoch 91/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.3733 - accuracy: 0.8237\n",
            "Epoch 92/100\n",
            "94/94 [==============================] - 1s 7ms/step - loss: 0.3728 - accuracy: 0.8301\n",
            "Epoch 93/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.3717 - accuracy: 0.8294\n",
            "Epoch 94/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.3710 - accuracy: 0.8298\n",
            "Epoch 95/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.3704 - accuracy: 0.8311\n",
            "Epoch 96/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.3702 - accuracy: 0.8301\n",
            "Epoch 97/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.3704 - accuracy: 0.8264\n",
            "Epoch 98/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.3708 - accuracy: 0.8308\n",
            "Epoch 99/100\n",
            "94/94 [==============================] - 1s 7ms/step - loss: 0.3685 - accuracy: 0.8291\n",
            "Epoch 100/100\n",
            "94/94 [==============================] - 1s 7ms/step - loss: 0.3678 - accuracy: 0.8324\n",
            "12/44 [=======>......................] - ETA: 0s - loss: 0.5764 - accuracy: 0.7266"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-02-02 01:10:20.237453: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6011 - accuracy: 0.7136\n",
            "[0.6010532975196838, 0.713575005531311]\n",
            "Classification Report: - \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.68      0.78      1033\n",
            "           1       0.48      0.80      0.60       374\n",
            "\n",
            "    accuracy                           0.71      1407\n",
            "   macro avg       0.69      0.74      0.69      1407\n",
            "weighted avg       0.79      0.71      0.73      1407\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-02-02 01:10:20.558993: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        }
      ],
      "source": [
        "x_train, y_train = training_batch(df3_0, df3_1, 0, 1495)\n",
        "\n",
        "y_pred1 = ANN(x_train, y_train, x_test, y_test, 'binary_crossentropy', -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            " 7/94 [=>............................] - ETA: 0s - loss: 0.7018 - accuracy: 0.5000  "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-02-02 01:10:21.500288: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "94/94 [==============================] - 2s 7ms/step - loss: 0.6290 - accuracy: 0.6625\n",
            "Epoch 2/100\n",
            "94/94 [==============================] - 1s 7ms/step - loss: 0.5388 - accuracy: 0.7391\n",
            "Epoch 3/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.5192 - accuracy: 0.7482\n",
            "Epoch 4/100\n",
            "94/94 [==============================] - 1s 8ms/step - loss: 0.5106 - accuracy: 0.7565\n",
            "Epoch 5/100\n",
            "94/94 [==============================] - 1s 9ms/step - loss: 0.5048 - accuracy: 0.7542\n",
            "Epoch 6/100\n",
            "94/94 [==============================] - 1s 7ms/step - loss: 0.5012 - accuracy: 0.7595\n",
            "Epoch 7/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4991 - accuracy: 0.7555\n",
            "Epoch 8/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4959 - accuracy: 0.7599\n",
            "Epoch 9/100\n",
            "94/94 [==============================] - 1s 7ms/step - loss: 0.4937 - accuracy: 0.7575\n",
            "Epoch 10/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4919 - accuracy: 0.7582\n",
            "Epoch 11/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4909 - accuracy: 0.7579\n",
            "Epoch 12/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4885 - accuracy: 0.7676\n",
            "Epoch 13/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4891 - accuracy: 0.7599\n",
            "Epoch 14/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4870 - accuracy: 0.7639\n",
            "Epoch 15/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4848 - accuracy: 0.7652\n",
            "Epoch 16/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4837 - accuracy: 0.7642\n",
            "Epoch 17/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4827 - accuracy: 0.7682\n",
            "Epoch 18/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4809 - accuracy: 0.7629\n",
            "Epoch 19/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4795 - accuracy: 0.7692\n",
            "Epoch 20/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4789 - accuracy: 0.7666\n",
            "Epoch 21/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4775 - accuracy: 0.7676\n",
            "Epoch 22/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4765 - accuracy: 0.7682\n",
            "Epoch 23/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4733 - accuracy: 0.7753\n",
            "Epoch 24/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4729 - accuracy: 0.7689\n",
            "Epoch 25/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4724 - accuracy: 0.7729\n",
            "Epoch 26/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4713 - accuracy: 0.7739\n",
            "Epoch 27/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4713 - accuracy: 0.7753\n",
            "Epoch 28/100\n",
            "94/94 [==============================] - 1s 7ms/step - loss: 0.4686 - accuracy: 0.7776\n",
            "Epoch 29/100\n",
            "94/94 [==============================] - 1s 7ms/step - loss: 0.4662 - accuracy: 0.7789\n",
            "Epoch 30/100\n",
            "94/94 [==============================] - 1s 7ms/step - loss: 0.4652 - accuracy: 0.7789\n",
            "Epoch 31/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4640 - accuracy: 0.7783\n",
            "Epoch 32/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4630 - accuracy: 0.7796\n",
            "Epoch 33/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4619 - accuracy: 0.7816\n",
            "Epoch 34/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4609 - accuracy: 0.7836\n",
            "Epoch 35/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4598 - accuracy: 0.7843\n",
            "Epoch 36/100\n",
            "94/94 [==============================] - 1s 7ms/step - loss: 0.4588 - accuracy: 0.7829\n",
            "Epoch 37/100\n",
            "94/94 [==============================] - 1s 7ms/step - loss: 0.4579 - accuracy: 0.7856\n",
            "Epoch 38/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4559 - accuracy: 0.7880\n",
            "Epoch 39/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4551 - accuracy: 0.7880\n",
            "Epoch 40/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4537 - accuracy: 0.7906\n",
            "Epoch 41/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4535 - accuracy: 0.7913\n",
            "Epoch 42/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4514 - accuracy: 0.7870\n",
            "Epoch 43/100\n",
            "94/94 [==============================] - 1s 7ms/step - loss: 0.4502 - accuracy: 0.7866\n",
            "Epoch 44/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4503 - accuracy: 0.7923\n",
            "Epoch 45/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4494 - accuracy: 0.7906\n",
            "Epoch 46/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4495 - accuracy: 0.7933\n",
            "Epoch 47/100\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.4466 - accuracy: 0.7943\n",
            "Epoch 48/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4452 - accuracy: 0.7936\n",
            "Epoch 49/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4447 - accuracy: 0.7943\n",
            "Epoch 50/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4460 - accuracy: 0.7943\n",
            "Epoch 51/100\n",
            "94/94 [==============================] - 1s 7ms/step - loss: 0.4431 - accuracy: 0.7946\n",
            "Epoch 52/100\n",
            "94/94 [==============================] - 1s 7ms/step - loss: 0.4417 - accuracy: 0.7973\n",
            "Epoch 53/100\n",
            "94/94 [==============================] - 1s 7ms/step - loss: 0.4397 - accuracy: 0.7967\n",
            "Epoch 54/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4387 - accuracy: 0.8010\n",
            "Epoch 55/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4398 - accuracy: 0.7977\n",
            "Epoch 56/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4372 - accuracy: 0.8013\n",
            "Epoch 57/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4366 - accuracy: 0.7993\n",
            "Epoch 58/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4357 - accuracy: 0.8000\n",
            "Epoch 59/100\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.4339 - accuracy: 0.8020\n",
            "Epoch 60/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4340 - accuracy: 0.8043\n",
            "Epoch 61/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4340 - accuracy: 0.8043\n",
            "Epoch 62/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4306 - accuracy: 0.8100\n",
            "Epoch 63/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4318 - accuracy: 0.8037\n",
            "Epoch 64/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4305 - accuracy: 0.8094\n",
            "Epoch 65/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4289 - accuracy: 0.8033\n",
            "Epoch 66/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4286 - accuracy: 0.8070\n",
            "Epoch 67/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4262 - accuracy: 0.8084\n",
            "Epoch 68/100\n",
            "94/94 [==============================] - 1s 7ms/step - loss: 0.4271 - accuracy: 0.8080\n",
            "Epoch 69/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4251 - accuracy: 0.8080\n",
            "Epoch 70/100\n",
            "94/94 [==============================] - 1s 7ms/step - loss: 0.4263 - accuracy: 0.8074\n",
            "Epoch 71/100\n",
            "94/94 [==============================] - 1s 7ms/step - loss: 0.4221 - accuracy: 0.8140\n",
            "Epoch 72/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4260 - accuracy: 0.8080\n",
            "Epoch 73/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4211 - accuracy: 0.8114\n",
            "Epoch 74/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.8077\n",
            "Epoch 75/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4195 - accuracy: 0.8090\n",
            "Epoch 76/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4211 - accuracy: 0.8127\n",
            "Epoch 77/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4186 - accuracy: 0.8117\n",
            "Epoch 78/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4172 - accuracy: 0.8144\n",
            "Epoch 79/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4184 - accuracy: 0.8140\n",
            "Epoch 80/100\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.4163 - accuracy: 0.8117\n",
            "Epoch 81/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4158 - accuracy: 0.8127\n",
            "Epoch 82/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4164 - accuracy: 0.8130\n",
            "Epoch 83/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4135 - accuracy: 0.8177\n",
            "Epoch 84/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4123 - accuracy: 0.8187\n",
            "Epoch 85/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4110 - accuracy: 0.8184\n",
            "Epoch 86/100\n",
            "94/94 [==============================] - 1s 7ms/step - loss: 0.4142 - accuracy: 0.8134\n",
            "Epoch 87/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4097 - accuracy: 0.8127\n",
            "Epoch 88/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4100 - accuracy: 0.8174\n",
            "Epoch 89/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4094 - accuracy: 0.8154\n",
            "Epoch 90/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4085 - accuracy: 0.8174\n",
            "Epoch 91/100\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.4094 - accuracy: 0.8174\n",
            "Epoch 92/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4067 - accuracy: 0.8187\n",
            "Epoch 93/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4039 - accuracy: 0.8224\n",
            "Epoch 94/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4021 - accuracy: 0.8194\n",
            "Epoch 95/100\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.4034 - accuracy: 0.8217\n",
            "Epoch 96/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4023 - accuracy: 0.8241\n",
            "Epoch 97/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4020 - accuracy: 0.8211\n",
            "Epoch 98/100\n",
            "94/94 [==============================] - 0s 5ms/step - loss: 0.4008 - accuracy: 0.8261\n",
            "Epoch 99/100\n",
            "94/94 [==============================] - 1s 7ms/step - loss: 0.4010 - accuracy: 0.8211\n",
            "Epoch 100/100\n",
            "94/94 [==============================] - 1s 8ms/step - loss: 0.4000 - accuracy: 0.8224\n",
            "23/44 [==============>...............] - ETA: 0s - loss: 0.5223 - accuracy: 0.7255"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-02-02 01:11:18.174087: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "44/44 [==============================] - 0s 4ms/step - loss: 0.5294 - accuracy: 0.7321\n",
            "[0.5294002890586853, 0.7320540547370911]\n",
            "Classification Report: - \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.74      0.80      1033\n",
            "           1       0.50      0.72      0.59       374\n",
            "\n",
            "    accuracy                           0.73      1407\n",
            "   macro avg       0.69      0.73      0.70      1407\n",
            "weighted avg       0.78      0.73      0.74      1407\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-02-02 01:11:18.473282: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        }
      ],
      "source": [
        "x_train, y_train = training_batch(df3_0, df3_1, 1495, 2990)\n",
        "\n",
        "y_pred2 = ANN(x_train, y_train, x_test, y_test, 'binary_crossentropy', -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            " 1/83 [..............................] - ETA: 23s - loss: 0.6912 - accuracy: 0.5938"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-02-02 01:11:18.785968: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "83/83 [==============================] - 1s 7ms/step - loss: 0.6175 - accuracy: 0.6767\n",
            "Epoch 2/100\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.5245 - accuracy: 0.7575\n",
            "Epoch 3/100\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.5019 - accuracy: 0.7685\n",
            "Epoch 4/100\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.4926 - accuracy: 0.7689\n",
            "Epoch 5/100\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.4860 - accuracy: 0.7700\n",
            "Epoch 6/100\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4826 - accuracy: 0.7734\n",
            "Epoch 7/100\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.4792 - accuracy: 0.7791\n",
            "Epoch 8/100\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.4773 - accuracy: 0.7723\n",
            "Epoch 9/100\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.4744 - accuracy: 0.7787\n",
            "Epoch 10/100\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.4737 - accuracy: 0.7776\n",
            "Epoch 11/100\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.4709 - accuracy: 0.7814\n",
            "Epoch 12/100\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.4693 - accuracy: 0.7787\n",
            "Epoch 13/100\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.4689 - accuracy: 0.7829\n",
            "Epoch 14/100\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.7825\n",
            "Epoch 15/100\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4646 - accuracy: 0.7848\n",
            "Epoch 16/100\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.4643 - accuracy: 0.7848\n",
            "Epoch 17/100\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.4626 - accuracy: 0.7818\n",
            "Epoch 18/100\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.4597 - accuracy: 0.7901\n",
            "Epoch 19/100\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.4585 - accuracy: 0.7882\n",
            "Epoch 20/100\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.4595 - accuracy: 0.7894\n",
            "Epoch 21/100\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.4576 - accuracy: 0.7898\n",
            "Epoch 22/100\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.4557 - accuracy: 0.7935\n",
            "Epoch 23/100\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.4559 - accuracy: 0.7947\n",
            "Epoch 24/100\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.4526 - accuracy: 0.7928\n",
            "Epoch 25/100\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.4519 - accuracy: 0.7924\n",
            "Epoch 26/100\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.4503 - accuracy: 0.7939\n",
            "Epoch 27/100\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.4499 - accuracy: 0.7932\n",
            "Epoch 28/100\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.4485 - accuracy: 0.7935\n",
            "Epoch 29/100\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.4471 - accuracy: 0.7958\n",
            "Epoch 30/100\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.4473 - accuracy: 0.7917\n",
            "Epoch 31/100\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.4445 - accuracy: 0.7996\n",
            "Epoch 32/100\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.4429 - accuracy: 0.7989\n",
            "Epoch 33/100\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.4413 - accuracy: 0.8000\n",
            "Epoch 34/100\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.4408 - accuracy: 0.8008\n",
            "Epoch 35/100\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.4410 - accuracy: 0.8030\n",
            "Epoch 36/100\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.4387 - accuracy: 0.7951\n",
            "Epoch 37/100\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.4370 - accuracy: 0.7981\n",
            "Epoch 38/100\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.4346 - accuracy: 0.8034\n",
            "Epoch 39/100\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.4340 - accuracy: 0.7985\n",
            "Epoch 40/100\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.4336 - accuracy: 0.8004\n",
            "Epoch 41/100\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.4319 - accuracy: 0.8057\n",
            "Epoch 42/100\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.4315 - accuracy: 0.8008\n",
            "Epoch 43/100\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.4289 - accuracy: 0.8034\n",
            "Epoch 44/100\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.4290 - accuracy: 0.8008\n",
            "Epoch 45/100\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.4277 - accuracy: 0.8057\n",
            "Epoch 46/100\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.4251 - accuracy: 0.8038\n",
            "Epoch 47/100\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.4286 - accuracy: 0.8011\n",
            "Epoch 48/100\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.4245 - accuracy: 0.8083\n",
            "Epoch 49/100\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.4240 - accuracy: 0.8019\n",
            "Epoch 50/100\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.4206 - accuracy: 0.8083\n",
            "Epoch 51/100\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4197 - accuracy: 0.8080\n",
            "Epoch 52/100\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.4194 - accuracy: 0.8102\n",
            "Epoch 53/100\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.4177 - accuracy: 0.8137\n",
            "Epoch 54/100\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4186 - accuracy: 0.8095\n",
            "Epoch 55/100\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4150 - accuracy: 0.8087\n",
            "Epoch 56/100\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4141 - accuracy: 0.8140\n",
            "Epoch 57/100\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4134 - accuracy: 0.8068\n",
            "Epoch 58/100\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.4116 - accuracy: 0.8129\n",
            "Epoch 59/100\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.4116 - accuracy: 0.8083\n",
            "Epoch 60/100\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.4100 - accuracy: 0.8133\n",
            "Epoch 61/100\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4086 - accuracy: 0.8129\n",
            "Epoch 62/100\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.4064 - accuracy: 0.8156\n",
            "Epoch 63/100\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.4072 - accuracy: 0.8163\n",
            "Epoch 64/100\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.4048 - accuracy: 0.8121\n",
            "Epoch 65/100\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.4037 - accuracy: 0.8171\n",
            "Epoch 66/100\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4033 - accuracy: 0.8201\n",
            "Epoch 67/100\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.4028 - accuracy: 0.8152\n",
            "Epoch 68/100\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.4009 - accuracy: 0.8133\n",
            "Epoch 69/100\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.3996 - accuracy: 0.8201\n",
            "Epoch 70/100\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.3975 - accuracy: 0.8250\n",
            "Epoch 71/100\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.3984 - accuracy: 0.8171\n",
            "Epoch 72/100\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.3974 - accuracy: 0.8209\n",
            "Epoch 73/100\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.3971 - accuracy: 0.8197\n",
            "Epoch 74/100\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.3934 - accuracy: 0.8213\n",
            "Epoch 75/100\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.3946 - accuracy: 0.8224\n",
            "Epoch 76/100\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.3936 - accuracy: 0.8254\n",
            "Epoch 77/100\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.3912 - accuracy: 0.8258\n",
            "Epoch 78/100\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.3896 - accuracy: 0.8285\n",
            "Epoch 79/100\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.3910 - accuracy: 0.8213\n",
            "Epoch 80/100\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.3889 - accuracy: 0.8269\n",
            "Epoch 81/100\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.3884 - accuracy: 0.8228\n",
            "Epoch 82/100\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.3872 - accuracy: 0.8296\n",
            "Epoch 83/100\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.3869 - accuracy: 0.8288\n",
            "Epoch 84/100\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.3858 - accuracy: 0.8254\n",
            "Epoch 85/100\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.3840 - accuracy: 0.8326\n",
            "Epoch 86/100\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.3832 - accuracy: 0.8269\n",
            "Epoch 87/100\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.3825 - accuracy: 0.8266\n",
            "Epoch 88/100\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.3805 - accuracy: 0.8315\n",
            "Epoch 89/100\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.3798 - accuracy: 0.8235\n",
            "Epoch 90/100\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.3810 - accuracy: 0.8269\n",
            "Epoch 91/100\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.3795 - accuracy: 0.8323\n",
            "Epoch 92/100\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.3780 - accuracy: 0.8296\n",
            "Epoch 93/100\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.3780 - accuracy: 0.8349\n",
            "Epoch 94/100\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.3744 - accuracy: 0.8323\n",
            "Epoch 95/100\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.3740 - accuracy: 0.8296\n",
            "Epoch 96/100\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.3744 - accuracy: 0.8326\n",
            "Epoch 97/100\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.3746 - accuracy: 0.8326\n",
            "Epoch 98/100\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.3714 - accuracy: 0.8338\n",
            "Epoch 99/100\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.3740 - accuracy: 0.8304\n",
            "Epoch 100/100\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.3692 - accuracy: 0.8338\n",
            "27/44 [=================>............] - ETA: 0s - loss: 0.5917 - accuracy: 0.7176"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-02-02 01:12:09.354556: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "44/44 [==============================] - 0s 4ms/step - loss: 0.6042 - accuracy: 0.7001\n",
            "[0.6041935086250305, 0.7000710964202881]\n",
            "Classification Report: - \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.66      0.76      1033\n",
            "           1       0.46      0.81      0.59       374\n",
            "\n",
            "    accuracy                           0.70      1407\n",
            "   macro avg       0.69      0.74      0.68      1407\n",
            "weighted avg       0.79      0.70      0.72      1407\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-02-02 01:12:09.653371: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        }
      ],
      "source": [
        "x_train, y_train = training_batch(df3_0, df3_1, 2990, 4130)\n",
        "\n",
        "y_pred3 = ANN(x_train, y_train, x_test, y_test, 'binary_crossentropy', -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = y_pred1.copy()\n",
        "for i in range(len(y_pred)):\n",
        "    x = y_pred1[i] + y_pred2[i] + y_pred3[i]\n",
        "\n",
        "    if x > 1:\n",
        "        y_pred[i] = 1\n",
        "    else:\n",
        "        y_pred[i] = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.70      0.79      1033\n",
            "           1       0.49      0.79      0.60       374\n",
            "\n",
            "    accuracy                           0.72      1407\n",
            "   macro avg       0.69      0.74      0.69      1407\n",
            "weighted avg       0.79      0.72      0.74      1407\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Customer Churn ANN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
